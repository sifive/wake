# Copyright 2024 SiFive, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You should have received a copy of LICENSE.Apache2 along with
# this software. If not, you may obtain a copy at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

package wake

# rscRunner: Creates a remote cache runner for a given api config
#
# ```
# rscRunner (RemoteCacheApi "local" 1234 "auth") = (Runner ...)
# ```
export target rscRunner (rscApi: RemoteCacheApi): Runner =
    mkRemoteCacheRunner rscApi (\_ Pass "") "/workspace" fuseRunner

# mkRemoteCacheRunner: Creates a remote cache runner from an underlying runner
#
# - `rscApi`: the remote cache to connect to
# - `hashFn`: a runner provided hash, used to invalate jobs that match by key but not by something
#   known only to the runner
# - `wakeroot`: Absolute path to the root of the wake project
# - `baseRunner`: The runner that should be used for a cache miss
# ```
# mkRemoteCacheRunner (RemoteCacheApi ...) (\_ Pass "") "" baseRunner = (Runner ...)
# ```
export def mkRemoteCacheRunner (rscApi: RemoteCacheApi) (hashFn: Result RunnerInput Error => Result String Error) (wakeroot: String) ((Runner name score baseDoIt): Runner): Runner =
    def virtual job stdout stderr status runtime cputime membytes ibytes obytes = prim "job_virtual"
    def badlaunch job error = prim "job_fail_launch"

    def doit job runnerInput = match runnerInput
        Fail e ->
            def _ = badlaunch job e

            Fail e
        Pass input ->
            def label = input.getRunnerInputLabel

            require Pass hashKey = hashFn runnerInput

            # -------------------------------------
            # --- Search the cache for the job  ---
            # -------------------------------------

            # Search the cache for a match
            def requestTask =
                rscApi
                | rscApiFindMatchingJob (mkSearchRequest input hashKey)

            require Pass response = requestTask
            else
                require Fail err = requestTask
                else unreachable "Result must be either Pass or Fail"

                # Always leave a breadcrumb since this should be a rare error.
                def _ = breadcrumb "{label}: Failed to search for job in the cache"

                # Leave detailed info if debugging is enabled
                def _ =
                    require True = shouldDebugRemoteCache Unit

                    def _ =
                        writeTempFile "remote.cache.lookup.fail" "label: {input.getRunnerInputLabel}\nerror: {err | format}"

                    True

                # This job isn't getting cached. That's probably preferable since the server
                # request failed but good to keep in mind.
                baseDoIt job (Pass input)

            # If a match was found use it
            require NoMatch = response
            else
                require (Match details) = response
                else unreachable "two-constructor tuple must have one value"

                def _ =
                    require True = shouldDebugRemoteCache Unit

                    def _ = breadcrumb "{label}: Found a match in the cache"

                    def _ =
                        writeTempFile "remote.cache.lookup.hit" "label: {input.getRunnerInputLabel}"

                    True

                def (
                    CacheSearchResponseMatch
                    outputSymlinks
                    outputDirs
                    outputFiles
                    stdoutBlob
                    stderrBlob
                    status
                    runtime
                    cputime
                    mem
                    ibytes
                    obytes
                ) = details

                # Start these downloads now since they aren't written to disk
                def stdoutDownload = rscApiGetStringBlob stdoutBlob
                def stderrDownload = rscApiGetStringBlob stderrBlob

                def doMakeDirectory (CacheSearchOutputDirectory path mode) =
                    # wake-format off
                    def cmd =
                        "mkdir",
                        "-m", "{strOctal mode}",
                        "-p", path,

                    require True =
                        makeExecPlan cmd Nil
                        | setPlanLabel "rsc: mkdir output dir {path}"
                        | runJobWith localRunner
                        | isJobOk
                    else failWithError "rsc: Failed to mkdir output dir: {path}"

                    Pass Unit

                # We need to create directories from shortest to longest, each directory along the
                # chain may have a different permission set and by creating short dirs first we
                # ensure they don't incorrectly inheret the permissions of a subdir. This required
                # ordering significantly decreases parallism, however this is mitigated by the fact
                # that most outputs are files, not dirs.
                def dirLoop (dirs: List CacheSearchOutputDirectory) = match dirs
                    Nil -> Pass Nil
                    h, t ->
                        require Pass dir = doMakeDirectory h
                        require Pass rest = dirLoop t

                        Pass (dir, rest)

                def lenOrder lhs rhs =
                    def lhsLen = lhs.getCacheSearchOutputDirectoryPath.strlen
                    def rhsLen = rhs.getCacheSearchOutputDirectoryPath.strlen

                    if lhsLen == rhsLen then
                        EQ
                    else if lhsLen < rhsLen then
                        LT
                    else
                        GT

                def orderedDirs =
                    outputDirs
                    | sortBy lenOrder

                # We don't actually care about the result here but we need to ensure that all
                # directories are created before potentially downloading files into them.
                require Pass _ = dirLoop orderedDirs
                else failWithError "rsc: Failed to make output directory"

                def doDownload (CacheSearchOutputFile path mode blob) =
                    rscApiGetFileBlob blob "{input.getRunnerInputDirectory}/{path}" mode

                # We don't actually care about the result here but we need to ensure that all
                # downloads have completed and succeeded before we attempt any symlinks/continue.
                require Pass _ =
                    outputFiles
                    | map doDownload
                    | findFail
                    | addErrorContext "rsc: Failed to download a blob"

                # TODO: These probably need to be wakeroot relative
                # Link must point to dest. We do the reverse here of what is done for posting a job
                def doMakeSymlink (CacheSearchOutputSymlink dest link) =
                    require True =
                        makeExecPlan
                        (
                            "ln",
                            "-s",
                            dest,
                            link,
                        )
                        Nil
                        | setPlanLabel "rsc: symlink {link} to {dest}"
                        | runJobWith localRunner
                        | isJobOk
                    else failWithError "rsc: Failed to link {link} to {dest}"

                    Pass Unit

                require Pass _ =
                    outputSymlinks
                    | map doMakeSymlink
                    | findFail
                    | addErrorContext "rsc: Failed to create a symlink"

                require Pass stdout =
                    stdoutDownload
                    | addErrorContext "rsc: Failed to download stdout for '{label}'"

                require Pass stderr =
                    stderrDownload
                    | addErrorContext "rsc: Failed to download stderr for '{label}'"

                def resolvedOutputs =
                    outputFiles
                    | map getCacheSearchOutputFilePath

                def resolvedSymlinks =
                    outputSymlinks
                    | map getCacheSearchOutputSymlinkPath

                def resolvedDirectories =
                    outputDirs
                    | map getCacheSearchOutputDirectoryPath

                def outputs = resolvedOutputs ++ resolvedDirectories ++ resolvedSymlinks
                def predict = Usage status runtime cputime mem ibytes obytes
                def _ = virtual job stdout stderr status runtime cputime mem ibytes obytes
                def inputs = map getPathName (input.getRunnerInputVisible)

                Pass (RunnerOutput inputs outputs predict)

            def _ =
                require True = shouldDebugRemoteCache Unit

                def _ = breadcrumb "{label}: Did not find a match"

                def _ =
                    writeTempFile "remote.cache.lookup.miss" "label: {input.getRunnerInputLabel}"

                True

            # -------------------------------------
            # --- Insert the job into the cache ---
            # -------------------------------------

            # Run the job to get the results
            require Pass output = baseDoIt job (Pass input)

            # Post the job to the server. This is left as 'def _' so that wake won't block progess
            # on it but it will stil be joined on before wake exits. Regardless of the result this
            # call should return the passing output to allow the build to continue.
            def _ = postJob rscApi job wakeroot hashKey input output

            Pass output

    Runner "remote-cache: {name}" score doit

## --- Helper functions ---

# Creates a CacheSearchRequest from the various inputs to a runner
def mkSearchRequest ((RunnerInput label cmd vis env dir stdin _res _prefix _usage isAtty): RunnerInput) (hidden: String) =
    CacheSearchRequest label cmd dir env hidden isAtty stdin vis

# Creates a CachePostJobRequest from the various inputs and outputs of a runner
def mkPostJobRequest ((RunnerInput label cmd vis env dir stdin _res _prefix _ isAtty): RunnerInput) (output: RunnerOutput) (hidden: String) (stdoutBlobId: String) (stderrBlobId: String) (files: List CachePostRequestOutputFile) (directories: List CachePostRequestOutputDirectory) (symlinks: List CachePostRequestOutputSymlink) =
    def Usage status runtime cputime mem ibytes obytes = output.getRunnerOutputUsage

    CachePostRequest
    label
    cmd
    dir
    env
    hidden
    isAtty
    stdin
    vis
    directories
    symlinks
    files
    stdoutBlobId
    stderrBlobId
    status
    runtime
    cputime
    mem
    ibytes
    obytes

export def thirdBy (acceptFn: a => Integer): (list: List a) => Triple (one: List a) (two: List a) (three: List a) =
    def loop list = match list
        Nil -> Triple Nil Nil Nil
        h, t ->
            # don't wait on f to process tail:
            def Triple x y z = loop t

            match (acceptFn h)
                1 -> Triple (h, x) y z
                2 -> Triple x (h, y) z
                3 -> Triple x y (h, z)
                _ -> Triple x y z

    loop

# Posts a completed job to the remote cache
def postJob (rscApi: RemoteCacheApi) (job: Job) (_wakeroot: String) (hidden: String) (input: RunnerInput) (output: RunnerOutput): Result Unit Error =
    require Pass stdout = job.getJobFailedStdoutRaw
    require Pass stderr = job.getJobFailedStderrRaw

    def allOutputs = output.getRunnerOutputOutputs

    def rmapStat path = match (unsafe_stat path)
        Fail x -> Fail x
        Pass x -> Pass (Pair path x)

    require Pass outputsStat =
        allOutputs
        | map rmapStat
        | findFail
        | addErrorContext "rsc: Failed to stat files to upload"

    def statToGroup (Stat t _ _) = match t
        PathTypeRegularFile -> 1
        PathTypeDirectory -> 2
        PathTypeSymlink -> 3
        _ -> panic "unsuported filetype for rsc"

    def (Triple regFiles directories symlinks) =
        outputsStat
        | thirdBy (\x x.getPairSecond.statToGroup)

    def uploadAndMakeFile (Pair path (Stat _ mode _)) =
        def doUpload =
            rscApi
            | rscApiPostFileBlob path path

        require Pass id = doUpload

        CachePostRequestOutputFile path (mode | mode2bits) id
        | Pass

    # TODO: readlink may need to be a PRIM for performance reasons
    # The path output by the job itself is the created symlink. The contents of the symlink
    # is the original file on disk. This is reversed when downloading a job.
    def makeSymlink (Pair link _) =
        require Pass dest =
            makeExecPlan
            (
                "readlink",
                "-n",
                link,
            )
            Nil
            | setPlanLabel "rsc: readlink {link}"
            | runJobWith localRunner
            | getJobStdout

        # TODO: Pretty sure this needs to be wakeroot relative
        CachePostRequestOutputSymlink dest link
        | Pass

    def makeDirectory (Pair path (Stat _ mode _)) =
        CachePostRequestOutputDirectory path (mode | mode2bits)

    def fileUploads =
        regFiles
        | map uploadAndMakeFile

    def symlinksUpload =
        symlinks
        | map makeSymlink

    def directoriesUpload =
        directories
        | map makeDirectory

    def stdoutUpload =
        rscApi
        | rscApiPostStringBlob "stdout" stdout

    def stderrUpload =
        rscApi
        | rscApiPostStringBlob "stderr" stderr

    require Pass stdoutId = stdoutUpload
    require Pass stderrId = stderrUpload

    require Pass uploads =
        fileUploads
        | findFail
        | addErrorContext "rsc: Failed to upload file"

    require Pass resolvedLinks =
        symlinksUpload
        | findFail
        | addErrorContext "rsc: Failed to resolve symlink"

    def req =
        mkPostJobRequest input output hidden stdoutId stderrId uploads directoriesUpload resolvedLinks

    rscApi
    | rscApiPostJob req

# Determines if the user has requested that debug info be emitted from the cache
target shouldDebugRemoteCache Unit: Boolean = match (getenv "DEBUG_WAKE_REMOTE_CACHE")
    Some _ -> True
    None -> False
