# Copyright 2019 SiFive, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You should have received a copy of LICENSE.Apache2 along with
# this software. If not, you may obtain a copy at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

package wake

export tuple Usage = # Unknown quantities are 0
    export Status: Integer
    export Runtime: Double
    export CPUtime: Double
    export MemBytes: Integer
    export InBytes: Integer
    export OutBytes: Integer

export def getUsageThreads (Usage _ run cpu _ _ _: Usage): Double =
    if run ==. 0.0 then
        cpu
    else
        cpu /. run

# RunnerInput is a subset of the fields supplied in the execution Plan
export tuple RunnerInput =
    export Label: String
    export Command: List String
    export Visible: List Path
    export Environment: List String
    export Directory: String
    export Stdin: String
    export Resources: List String
    # A unique prefix for this job
    export Prefix: String
    # Previous resource usage
    export Record: Usage
    # Determines if job should run in psuedoterminal
    export IsAtty: Boolean

export tuple RunnerOutput =
    export Inputs: List String
    export Outputs: List String
    export Usage: Usage

# A Runner describes a way to invoke a Plan to get a Job
export tuple Runner =
    export Name: String
    export Score: Plan => Result Double String
    Fn: Job => Result RunnerInput Error => Result RunnerOutput Error

# Create new Runner given pre- and post-hooks around an existing Runner
# param name: String
# param score: type Plan → Result Double String
#   Called by runJob to produce a score representing the priority of a runner with respect to the given Plan.
# param pre: type Result RunnerInput Error → Pair (Result RunnerInput Error) a
#   Called before the job is run, allowing the runner to modify the input to provide the requested resources.
# param post: type Pair (Result RunnerOutput Error) a → Result RunnerOutput Error
#   Similar to the pre function but called after the job has run. post is for editing the reported outputs/inputs/usage of the job.
# param (Runner _ _ run): base runner that the current runner is built on top of
#   i.e. localRISCVRunner is built on localRunner.

export def makeRunner name score pre post (Runner _ _ run) =
    def doit job preInput = match (pre preInput)
        Pair runInput state =
            def runOutput = run job runInput
            def final _ = post (Pair runOutput state)

            # Don't run any 'post' steps until the Job has stopped running
            waitJobMerged final job

    Runner name score doit

export data Persistence =
    # Job should be re-executed on every runJob call.
    #
    # In this case, no job deduplication is performed and so it must
    # *not* write any files (stdout/stderr are fine) or be guaranteed to only be
    # encountered once in any wake execution anyway.
    ReRun
    # Job should only be run once in a given wake execution.
    Once
    # Job should output be reusable between wake invocations.
    Keep
    # Job should output be shared between workspaces.
    Share

# A Plan describes a not-yet-executed Job
export tuple Plan =
    # The label used when showing the command during execution. This is recommended for efficient
    # debugging and locating job information. For example, the label will show up in the terminal during
    # job execution, in a job's progress bar in the terminal, when running the `wake --last` command,
    # and in the `spec-<jobid>.json` and `result-<jobid>.json` files in the `.build` directory.
    export Label: String
    # The command-line arguments (the first is the command to run)
    export Command: List String
    # Only these files and directories should be available to the command
    export Visible: List Path
    # KEY=VALUE environment variables fed to the command
    export Environment: List String
    # The working directory in which the command should be run
    export Directory: String
    # The file to which standard input should be connected.
    # An empty string `""` is interpreted as there being no `stdin` file.
    export Stdin: String
    # How should standard output be displayed during a build
    export Stdout: LogLevel
    # How should standard error be displayed during a build
    export Stderr: LogLevel
    # Echo the command to this stream
    export Echo: LogLevel
    # See Persistence table above
    export Persistence: Persistence
    # The resources a runner must provide to the job (licenses/etc).
    # These strings are uninterpreted and are only meaningful to the right runners.
    export Resources: List String
    # User-supplied usage prediction; overruled by database statistics (if any)
    export Usage: Usage
    # Modify the Runner's reported inputs (files read). For advanced use only.
    export FnInputs: (List String => List String)
    # Modify the Runner's reported outputs (files created). Use this to provide a function to filter out
    # files that you do not require use of. For normal use, use `setPlanFilterOutputs` to set this field.
    # Setting this field directly is for advanced use only.
    export FnOutputs: (List String => List String)
    # Determines if job should run in psuedoterminal
    export IsAtty: Boolean

def isOnce: Persistence => Boolean = match _
    ReRun = False
    _ = True

def isKeep: Persistence => Boolean = match _
    ReRun = False
    Once = False
    _ = True

def isShare: Persistence => Boolean = match _
    Share = True
    _ = False

# Convenience accessor methods

export def getPlanOnce p =
    isOnce (getPlanPersistence p)

export def getPlanKeep p =
    isKeep (getPlanPersistence p)

export def getPlanShare p =
    isShare (getPlanPersistence p)

# Convenience set methods

# Sets the `FnOutputs` field in a `Plan` by using the given filter function to filter out unneeded files created
# during a job. This function is recommended over directly setting the `FnOutputs` field with `setPlanFnOutputs`.
#
# Parameters:
#  - `filterFn`: Determines whether to keep a file that was created or not. True means keep the file.
export def setPlanFilterOutputs (filterFn: (file: String) => Boolean): Plan => Plan =
    # This implementation prevents any unintentional abuse of the FnOutputs field, which can be used to
    # actually add files. This method here only supports filtering.
    def fnOutputs (files: List String): List String = filter filterFn files

    setPlanFnOutputs fnOutputs

# If `Once` is set to `False`, no job deduplication is performed and so it must
# *not* write any files (stdout/stderr are fine) or be guaranteed to only be
# encountered once in any wake execution anyway.
export def setPlanOnce v p =
    editPlanOnce (\_ v) p

export def setPlanKeep v p =
    editPlanKeep (\_ v) p

export def setPlanShare v p =
    editPlanShare (\_ v) p

# Prepend 'value' to the Plan's 'PATH' environment value
export def prependPlanPath (value: String) (plan: Plan): Plan =
    editPlanEnvironment (addEnvironmentPath value) plan

# Set an environment variable in a Plan
export def setPlanEnvVar (name: String) (value: String) (plan: Plan): Plan =
    editPlanEnvironment ("{name}={value}", _) plan

# Helper methods that maintain the invariant that: Share => Keep => Once

# If `Once` is set to `False`, no job deduplication is performed and so it must
# *not* write any files (stdout/stderr are fine) or be guaranteed to only be
# encountered once in any wake execution anyway.
export def editPlanOnce (f: Boolean => Boolean): Plan => Plan =
    def helper = match _
        ReRun if f False = Once
        Once if ! f True = ReRun
        Keep if ! f True = ReRun
        Share if ! f True = ReRun
        x = x

    editPlanPersistence helper

export def editPlanKeep (f: Boolean => Boolean): Plan => Plan =
    def helper = match _
        ReRun if f False = Keep
        Once if f False = Keep
        Keep if ! f True = Once
        Share if ! f True = Once
        x = x

    editPlanPersistence helper

export def editPlanShare (f: Boolean => Boolean): Plan => Plan =
    def helper = match _
        ReRun if f False = Share
        Once if f False = Share
        Keep if f False = Share
        Share if ! f True = Keep
        x = x

    editPlanPersistence helper

# Get a unique hash-code for the job
export def getPlanHash (plan: Plan): Integer =
    def Plan _ cmd _ env dir stdin _ _ _ _ _ _ _ _ isAtty = plan
    def isAttyStr = if isAtty then "true" else "false"

    def sig =
        (
            isAttyStr,
            "\0\0",
            implode cmd,
            "\0\0",
            implode env,
            "\0\0",
            dir,
            "\0\0",
            stdin,
        )
        | cat

    require Some out = intbase 16 (hashString sig)
    else unreachable "hash_str returned a non-hex string!!!"

    out

# The criteria which determine if Job execution can be skipped:
#   Once  is True and a matching job was run by this wake invocation
#   Keep  is True and there is matching output in the workspace
#   Share is True and there is matching output in a shared cache
# A Job is considered matching if:
#   The Command, Environment, Directory, and Stdin are exact matches
#   FnInputs, FnOutputs have the same hashcode
# Output is considered matching if:
#   The prior Outputs exist as the output of a matching Job
#   The prior Input files have the same hashes as files in the workspace
#   The prior Input dirs observe the same set of Visible files

# Create a labeled shell plan.
export def makePlan (label: String) (visible: List Path) (command: String): Plan =
    makeShellPlan command visible
    | setPlanLabel label

# Identity function
def id x =
    x

def bToInt b =
    if b then 1 else 0

# Set reasonable defaults for all Plan arguments
export def makeExecPlan (cmd: List String) (visible: List Path): Plan =
    Plan "" cmd visible environment "." "" logInfo logWarning logEcho Share Nil defaultUsage id id False

export def makeShellPlan (script: String) (visible: List Path): Plan =
    makeExecPlan (which "dash", "-c", script, Nil) visible

def defaultUsage =
    Usage 0 0.0 1.0 0 0 0

# This runner does not detect inputs/outputs on it's own
# You must use Fn{Inputs,Outputs} to fill in this information
export def localRunner: Runner =
    def launch job dir stdin env cmd status runtime cputime membytes ibytes obytes isatty =
        prim "job_launch"

    def badlaunch job error = prim "job_fail_launch"

    def doit job = match _
        Fail e =
            def _ = badlaunch job e

            Fail e
        Pass (RunnerInput _ cmd vis env dir stdin _ _ predict isatty) =
            def Usage status runtime cputime mem in out = predict

            def _ =
                launch job dir stdin env.implode cmd.implode status runtime cputime mem in out (bToInt isatty)

            match (getJobReality job)
                Pass reality = Pass (RunnerOutput (map getPathName vis) Nil reality)
                Fail f = Fail f

    def score _ = Pass 1.0

    Runner "local" score doit

# TODO: Delete these once new json API is added to wake repo
def jField (jvalue: JValue) (key: String) =
    require JObject obj = jvalue
    else failWithError "not an object"

    require Some (Pair (Pair _ value) _) = find (_.getPairFirst ==~ key) obj
    else failWithError "key '{key}' not found"

    Pass value

def jInteger = match _
    Pass (JInteger x) = Pass x
    Fail err = Fail err
    _ = failWithError "not an integer"

def jString = match _
    Pass (JString x) = Pass x
    Fail err = Fail err
    _ = failWithError "not a string"

def jDouble = match _
    Pass (JDouble x) = Pass x
    Fail err = Fail err
    _ = failWithError "not a number"

def jArray (fn: Result JValue Error => Result a Error) = match _
    Pass (JArray arr) =
        map (fn _.Pass) arr
        | findFail
    Fail err = Fail err
    _ = failWithError "not an array"

def getPath input =
    require Pass elem = input

    jField elem "path"
    | jString

# wakeroot is the absolute sandbox-path from which input and output files will
# be interpreted as being relative to if they're in fact relative.
export def mkJobCacheRunner (hashFn: Result RunnerInput Error => Result String Error) (wakeroot: String) ((Runner name score baseDoIt): Runner): Runner =
    def virtual job stdout stderr status runtime cputime membytes ibytes obytes = prim "job_virtual"
    def badlaunch job error = prim "job_fail_launch"
    def job_cache_read str = prim "job_cache_read"
    def job_cache_add str = prim "job_cache_add"

    def doit job runnerInput = match runnerInput
        Fail e =
            def _ = badlaunch job e

            Fail e
        Pass (RunnerInput label cmd vis env dir stdin _ prefix _ _) =
            def mkVisJson (Path path hash) =
                JObject (
                    "path" :-> JString path,
                    "hash" :-> JString hash,
                )

            def jobCacheVisible = JArray (map mkVisJson vis)

            require Pass hashKey = hashFn runnerInput

            def jobCacheJsonIn =
                prettyJSON
                $ JObject (
                    "wakeroot" :-> JString wakeroot,
                    "cwd" :-> JString dir,
                    "command_line" :-> JString cmd.implode,
                    "envrionment" :-> JString env.implode,
                    "stdin" :-> JString stdin,
                    "input_files" :-> jobCacheVisible,
                    "client_cwd" :-> JString workspace,
                    "runner_hash" :-> JString hashKey,
                    "dir_redirects" :-> JObject (wakeroot :-> JString "./",),
                )

            require Pass cacheResult =
                job_cache_read jobCacheJsonIn
                | rmapFail failWithError

            require Pass jobCacheJsonOut = parseJSONBody cacheResult

            require Pass (JBoolean cacheHit) = jField jobCacheJsonOut "found"
            else failWithError "job-cache returned unexpected json schema"

            def isDebugOn =
                require Some value = getenv "DEBUG_WAKE_SHARED_CACHE"
                else False

                value ==~ "1"

            require False = cacheHit
            else
                def _ =
                    require True = isDebugOn

                    def _ = write ".cache-hit/read.{prefix}.json" "//{label}\n{jobCacheJsonIn}"
                    def _ = write ".cache-hit/out.{prefix}.json" "//{label}\n{cacheResult}"

                    True

                require Pass match_info = jField jobCacheJsonOut "match"
                require Pass output_info = jField match_info "output_info"

                require Pass status =
                    jField output_info "status"
                    | jInteger

                require Pass runtime =
                    jField output_info "runtime"
                    | jDouble

                require Pass cputime =
                    jField output_info "cputime"
                    | jDouble

                require Pass mem =
                    jField output_info "mem"
                    | jInteger

                require Pass ibytes =
                    jField output_info "ibytes"
                    | jInteger

                require Pass obytes =
                    jField output_info "obytes"
                    | jInteger

                require Pass inputs =
                    jField match_info "input_files"
                    | jArray jString

                require Pass output_files =
                    jField match_info "output_files"
                    | jArray getPath

                require Pass output_dirs =
                    jField match_info "output_dirs"
                    | jArray getPath

                require Pass output_symlinks =
                    jField match_info "output_symlinks"
                    | jArray getPath

                require Pass stdout =
                    jField output_info "stdout"
                    | jString

                require Pass stderr =
                    jField output_info "stderr"
                    | jString

                def outputs = output_files ++ output_dirs ++ output_symlinks
                def predict = Usage status runtime cputime mem ibytes obytes
                def _ = virtual job stdout stderr status runtime cputime mem ibytes obytes

                Pass (RunnerOutput inputs outputs predict)

            def _ =
                require True = isDebugOn

                def _ = write ".cache-misses/read.{prefix}.json" "//{label}\n{jobCacheJsonIn}"

                True

            # Now we need to run the job
            require Pass (RunnerOutput inputs outputs useage) = baseDoIt job runnerInput

            def Usage status runtime cputime mem ibytes obytes = useage
            def inputsTree = listToTree scmpCanonical inputs

            def mkOutputFileJson src =
                JObject (
                    "src" :-> JString src,
                    "path" :-> JString "{wakeroot}/{src}",
                )

            def jobCacheOutputFiles = JArray (map mkOutputFileJson outputs)

            def jobCacheReadFiles =
                def readPaths = filter (tcontains _.getPathName inputsTree) vis

                JArray (map mkVisJson readPaths)

            require Pass stdout = getJobStdout job
            require Pass stderr = getJobStderr job

            def jobCacheAddJson =
                prettyJSON
                $ JObject (
                    "wakeroot" :-> JString wakeroot,
                    "cwd" :-> JString dir,
                    "command_line" :-> JString cmd.implode,
                    "envrionment" :-> JString env.implode,
                    "stdin" :-> JString stdin,
                    "runner_hash" :-> JString hashKey,
                    "input_files" :-> jobCacheReadFiles,
                    "input_dirs" :-> JArray Nil, # TODO: This will need some fuse work to make good on
                    "output_files" :-> jobCacheOutputFiles,
                    "status" :-> JInteger status,
                    "runtime" :-> JDouble runtime,
                    "cputime" :-> JDouble cputime,
                    "mem" :-> JInteger mem,
                    "ibytes" :-> JInteger ibytes,
                    "obytes" :-> JInteger obytes,
                    "stdout" :-> JString stdout,
                    "stderr" :-> JString stderr,
                    "client_cwd" :-> JString workspace,
                )

            # We put this in a def so that it does not block the return below.
            # This ensures that the effect still occurs and blocks wake finishing but the job
            # itself is not blocked by writing to the cache. This allows us to tolorate a lot
            # of slow down on cache writing.
            def _ =
                def _ =
                    require True = isDebugOn

                    def _ = write ".cache-misses/write.{prefix}.json" "//{label}\n{jobCacheAddJson}"

                    True

                # Caching a failed job is a waste of space, never do that
                require True = status == 0
                else Pass ""

                # Sometimes we want a read-only cache. For instance read-only pre-merge
                # with read-write post-merge.
                require None = getenv "WAKE_LOCAL_JOB_CACHE_READ_ONLY"
                else Pass ""

                job_cache_add jobCacheAddJson

            Pass (RunnerOutput (map getPathName vis) outputs useage)

    Runner "job-cache: {name}" score doit

export def virtualRunner: Runner =
    def virtual job stdout stderr status runtime cputime membytes ibytes obytes = prim "job_virtual"
    def badlaunch job error = prim "job_fail_launch"

    def doit job = match _
        Fail e =
            def _ = badlaunch job e

            Fail e
        Pass (RunnerInput _ _ vis _ _ _ _ _ predict _) =
            def Usage status runtime cputime mem in out = predict

            def _ =
                virtual job "" "" status runtime cputime mem in out # sets predict+reality

            match (getJobReality job)
                Pass reality = Pass (RunnerOutput (map getPathName vis) Nil reality)
                Fail f = Fail f

    Runner "virtual" (\_ Pass 0.0) doit

def implode l =
    cat (foldr (_, "\0", _) Nil l)

def runAlways cmd env dir stdin res uusage finputs foutputs vis keep run echo stdout stderr label isatty: Job =
    def create label dir stdin env cmd signature visible keep echo stdout stderr isatty =
        prim "job_create"

    def finish job inputs outputs all_outputs status runtime cputime membytes ibytes obytes =
        prim "job_finish"

    def badfinish job error = prim "job_fail_finish"
    def cache dir stdin env cmd signature visible isatty = prim "job_cache"
    def signature cmd res fni fno keep = prim "hash"
    def hash = signature cmd res finputs foutputs keep

    def build Unit =
        def visStrings = map getPathName vis

        def job =
            create
            label
            dir
            stdin
            env.implode
            cmd.implode
            hash
            visStrings.implode
            (bToInt keep)
            echo
            stdout
            stderr
            (bToInt isatty)

        def prefix = str (getJobId job)

        def usage =
            getJobRecord job
            | getOrElse uusage

        def output =
            run job (Pass (RunnerInput label cmd vis env dir stdin res prefix usage isatty))

        def final _ = match output
            Fail e = badfinish job e
            Pass (RunnerOutput inputs outputs (Usage status runtime cputime mem in out)) =
                def input =
                    finputs inputs
                    | map simplify
                    | implode

                def output =
                    foutputs outputs
                    | computeHashes prefix
                    | implode

                finish job input output (implode outputs) status runtime cputime mem in out

        # Make sure we don't hash files before the job has stopped running
        def _ = waitJobMerged final job

        job

    def confirm abort last job =
        # notOk cannot be deadcode eliminated thanks to printlnLevel having effects
        def notOk (Pair name hash) =
            if hashcode name ==* hash then
                Unit
            else if abort # The panic will not be deadcode dropped, because it's an alternative return of the effect-ful notOk
            then
                panic "The hashcode of output file '{name}' has changed from {hash} (when wake last ran) to {hashcode name} (when inspected this time). Presumably it was hand edited. Please move this file out of the way. Aborting the build to prevent loss of your data."
            else
                printlnLevel
                logError
                "Wake was run with '-c' and the hashcode of output file '{name}' has changed, despite being produced from identical inputs. In the prior run, it was {hash} and now it is {hashcode name}. Hashes of dependent jobs using this file will not be checked."

        def _ = waitJobMerged (\_ map notOk last) job

        job

    match keep
        False = build Unit
        True =
            match (cache dir stdin env.implode cmd.implode hash (map getPathName vis).implode (bToInt isatty))
                Pair (job, _) last = confirm True last job
                Pair Nil last = confirm False last (build Unit)

# Only run if the first four arguments differ
target runOnce cmd env dir stdin vis isatty run \ res usage finputs foutputs keep echo stdout stderr label =
    runAlways cmd env dir stdin res usage finputs foutputs vis keep run echo stdout stderr label isatty

export def runJobImp label cmd env dir stdin res usage finputs foutputs vis pers run (LogLevel echo) (LogLevel stdout) (LogLevel stderr) isatty =
    if isOnce pers then
        runOnce
        cmd
        env
        dir
        stdin
        vis
        isatty
        run
        res
        usage
        finputs
        foutputs
        (isKeep pers)
        echo
        stdout
        stderr
        label
    else
        runAlways
        cmd
        env
        dir
        stdin
        res
        usage
        finputs
        foutputs
        vis
        (isKeep pers)
        run
        echo
        stdout
        stderr
        label
        isatty

export def runJobWith (Runner _ _ run) (Plan label cmd vis env dir stdin stdout stderr echo pers res usage finputs foutputs isatty) =
    runJobImp label cmd env dir stdin res usage finputs foutputs vis pers run echo stdout stderr isatty

# Set the value of a tag on a Job
# This is useful for post-build reflection into the database
export def setJobTag (key: String) (value: String) (job: Job): Job =
    def p job key value = prim "job_tag"
    def _ = p job key value

    job

def toUsage (Pair (Pair status runtime) (Pair (Pair cputime membytes) (Pair ibytes obytes))) =
    Usage status runtime cputime membytes ibytes obytes

def getJobReality (job: Job): Result Usage Error =
    def raw job = prim "job_reality"

    raw job
    | rmap toUsage

def waitJobMerged (f: Unit => a) (job: Job): a =
    def raw job = prim "job_reality"

    wait (\_ f Unit) (raw job)

# Actual usage of a finished job
export def getJobReport (job: Job): Result Usage Error =
    def raw job = prim "job_report"

    raw job
    | rmap toUsage

# From database, available the moment a Job exists
export def getJobRecord (job: Job): Option Usage =
    def raw job = prim "job_record"

    raw job
    | at 0
    | omap toUsage

# Control a running/finished Job
def stdio job fd =
    prim "job_output" # 1=stdout, 2=stderr; blocks till closed

def tree job typ =
    prim "job_tree" # 0=visible, 1=input, 2=output; blocks till finished

def treeOk file =
    def Pair f h = file

    match h
        "BadHash" = failWithError "Could not hash {f}"
        _ = Pass (Path f h)

def guardPath job = match _
    Fail e = Fail e
    Pass l if job.isJobOk = findFailFn treeOk l
    _ =
        failWithError
        "Non-zero exit status ({format job.getJobStatus}) for job {str job.getJobId}: '{job.getJobDescription}'"

def mapPath = match _
    Fail e = Fail e
    Pass l = findFailFn treeOk l

export def getJobStdoutRaw (job: Job): Result String Error =
    stdio job 1

export def getJobStderrRaw (job: Job): Result String Error =
    stdio job 2

export def getJobStdout (job: Job): Result String Error =
    require Pass stdout = getJobStdoutRaw job

    Pass (stdout | filterTerminalCodes)

export def getJobStderr (job: Job): Result String Error =
    require Pass stderr = getJobStderrRaw job

    Pass (stderr | filterTerminalCodes)

export def getJobInputs (job: Job): Result (List Path) Error =
    tree job 1
    | guardPath job

export def getJobOutputs (job: Job): Result (List Path) Error =
    tree job 2
    | guardPath job

export def getJobFailedInputs (job: Job): Result (List Path) Error =
    tree job 1
    | mapPath

export def getJobFailedOutputs (job: Job): Result (List Path) Error =
    tree job 2
    | mapPath

export def getJobId (job: Job): Integer =
    (\j prim "job_id") job

export def getJobDescription (job: Job): String =
    (\j prim "job_desc") job

export def getJobOutput (job: Job): Result Path Error =
    require Pass outputs = getJobOutputs job

    match outputs
        Nil =
            failWithError "No outputs available from job {str job.getJobId}: '{job.getJobDescription}'"
        (singleOutput, Nil) = Pass singleOutput
        _ =
            failWithError "More than one output found from job {str job.getJobId}: '{job.getJobDescription}'"

export def isJobOk (job: Job): Boolean = match (getJobReport job)
    Fail _ = False
    Pass u = u.getUsageStatus == 0

export data Status =
    Exited Integer
    Signaled Integer
    Aborted Error

export def getJobStatus (job: Job): Status = match (getJobReport job)
    Fail f = Aborted f
    Pass u =
        def status = u.getUsageStatus

        if status >= 0 then
            Exited status
        else
            Signaled (-status)

# Location of the wake executable
export def wakePath: String =
    prim "execpath"

# Implement FUSE-based Runner
export def fuseRunner: Runner =
    def fuse = "{wakePath}/wakebox"
    def score _ = Pass 2.0

    makeJSONRunnerPlan fuse score
    | editJSONRunnerPlanExtraEnv (editEnvironment "DEBUG_FUSE_WAKE" (\_ getenv "DEBUG_FUSE_WAKE"))
    | makeJSONRunner

export def rOK: Integer =
    0

export def wOK: Integer =
    1

export def xOK: Integer =
    2

export def access (file: String) (mode: Integer): Boolean =
    (\f \m prim "access") file mode

export def defaultRunner: Runner =
    require Some _ = getenv "WAKE_LOCAL_JOB_CACHE"
    else fuseRunner

    # The fuseRunner does not actully mount over / and instead uses the
    # the host root as the sandbox root. This means that wakeroot will
    # change from depending on where wake is being run from. As a hack
    # to work around this we abuse the fact that the fuseRunner only
    # works in relative paths to make different runs consistent. Ideally
    # you'd have a more complex sandbox that kept the wakeroot at a
    # consistent place across runs.
    mkJobCacheRunner (\_ Pass "") "/workspace" fuseRunner

# A plan describing how to construct a JSONRunner
# RawScript: the path to the script to run jobs with
# ExtraArgs: extra arguments to pass to ``RawScript``
# ExtraEnv: environment variables to pass to the script
# Score: runJob chooses the runner with the largest score for a Plan
# Estimate: predict local usage based on prior recorded usage
tuple JSONRunnerPlan =
    export RawScript: String
    export ExtraArgs: List String
    export ExtraEnv: List String
    export Score: Plan => Result Double String
    export Estimate: Usage => Usage

# make a ``JSONRunnerPlan`` with ``Nil`` and ``(_)`` as defaults for ``ExtraArgs`` and ``Estimate`` respectively
# rawScript: String; the path to the script to run jobs with
# score: runJob chooses the runner with the largest score for a Plan
export def makeJSONRunnerPlan (rawScript: String) (score: Plan => Result Double String): JSONRunnerPlan =
    JSONRunnerPlan rawScript Nil Nil score (_)

# Make a Runner that runs a named script to run jobs
# plan: JSONRunnerPlan; a tuple containing the arguments for this function
export def makeJSONRunner (plan: JSONRunnerPlan): Runner =
    def rawScript = plan.getJSONRunnerPlanRawScript
    def extraArgs = plan.getJSONRunnerPlanExtraArgs
    def extraEnv = plan.getJSONRunnerPlanExtraEnv
    def score = plan.getJSONRunnerPlanScore
    def estimate = plan.getJSONRunnerPlanEstimate
    def script = which (simplify rawScript)
    def ok = access script xOK

    def pre = match _
        Fail f = Pair (Fail f) ""
        _ if !ok = Pair (Fail (makeError "Runner {script} is not executable")) ""
        Pass (RunnerInput label command visible environment directory stdin res prefix record isatty) =
            def Usage status runtime cputime membytes inbytes outbytes = record

            def json =
                JObject (
                    "label" :-> JString label,
                    "command" :-> command | map JString | JArray,
                    "environment" :-> environment | map JString | JArray,
                    "visible" :-> visible | map (_.getPathName.JString) | JArray,
                    "directory" :-> JString directory,
                    "stdin" :-> JString stdin,
                    "resources" :-> res | map JString | JArray,
                    "version" :-> JString version,
                    "isolate-network" :-> JBoolean False,
                    "isolate-pids" :-> JBoolean False,
                    "mount-ops" :-> JArray (JObject ("type" :-> JString "workspace", "destination" :-> JString ".", Nil), Nil),
                    "usage" :-> JObject (
                        "status" :-> JInteger status,
                        "runtime" :-> JDouble runtime,
                        "cputime" :-> JDouble cputime,
                        "membytes" :-> JInteger membytes,
                        "inbytes" :-> JInteger inbytes,
                        "outbytes" :-> JInteger outbytes,
                        Nil
                    ),
                    Nil
                )

            require Pass build =
                mkdir ".build"
                | rmap getPathName
            else Pair (Fail (makeError "Failed to 'mkdir .build'.")) ""

            def specFilePath = "{build}/spec-{prefix}.json"

            require Pass inFile =
                write specFilePath (prettyJSON json)
                | rmap getPathName
            else Pair (Fail (makeError "Failed to 'write {specFilePath}'.")) ""

            def outFile = resultPath inFile
            def cmd = script, "-I", "-p", inFile, "-o", outFile, extraArgs

            def proxy =
                RunnerInput label cmd Nil (extraEnv ++ environment) "." "" Nil prefix (estimate record) isatty

            Pair (Pass proxy) inFile

    def resultPath specPath = replace `spec-` "result-" specPath

    def post = match _
        Pair (Fail f) _ = Fail f
        Pair (Pass (RunnerOutput _ _ (Usage x _ _ _ _ _))) inFile if x != 0 =
            Fail (makeError "Non-zero exit status ({str x}) for JSON runner {script} on {inFile}")
        Pair (Pass _) inFile =
            def outFile = resultPath inFile
            def json = parseJSONFile (Path outFile "BadHash")

            match json
                Fail f = Fail f
                Pass content =
                    def _ = markFileCleanable outFile

                    def field name = match _ _
                        _ (Fail f) = Fail f
                        None (Pass fn) =
                            Fail "{script} produced {outFile}, which is missing usage/{name}"
                        (Some x) (Pass fn) = Pass (fn x)

                    def usage = content // `usage`

                    def usageResult =
                        Pass (Usage _ _ _ _ _ _)
                        | field "status" (usage // `status` | getJInteger)
                        | field "runtime" (usage // `runtime` | getJDouble)
                        | field "cputime" (usage // `cputime` | getJDouble)
                        | field "membytes" (usage // `membytes` | getJInteger)
                        | field "inbytes" (usage // `inbytes` | getJInteger)
                        | field "outbytes" (usage // `outbytes` | getJInteger)

                    def getK exp =
                        content // exp
                        | getJArray
                        | getOrElse Nil
                        | mapPartial getJString

                    match usageResult
                        Fail f = Fail (makeError f)
                        Pass usage = Pass (RunnerOutput (getK `inputs`) (getK `outputs`) usage)

    makeRunner "json-{script}" score pre post localRunner
