# Copyright 2019 SiFive, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You should have received a copy of LICENSE.Apache2 along with
# this software. If not, you may obtain a copy at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

tuple Usage =
  global Status:   Integer
  global Runtime:  Double
  global CPUtime:  Double
  global MemBytes: Integer
  global InBytes:  Integer
  global OutBytes: Integer

# RunnerInput is a subset of the fields supplied in the execution Plan
tuple RunnerInput =
  global Command:       List String
  global Visible:       List Path
  global Environment:   List String
  global Directory:     String
  global StandardInput: String
  global Resources:     List String
  global Prefix:        String        # a unique prefix for this job
  global Record:        Option Usage  # previous resource usage, if known
  Pool:                 Integer

tuple RunnerOutput =
  global Inputs:  List String
  global Outputs: List String
  global Indexes: List String
  global Usage:   Usage

# A Runner describes a way to invoke a Plan to get a Job
tuple Runner =
  global Name:  String
  global Score: Plan => Double
  Fn:           Job => RunnerInput => RunnerOutput

# Create new Runner given pre- and post-hooks around an existing Runner
global def makeRunner name score pre post (Runner _ _ run) =
  def doit job preInput =
    def preOutput = pre preInput
    # Ensure that match does not re-raise the exception; must invoke run!
    match (try (\_ Pair (cast preOutput) (cast preOutput)) preOutput)
      Pair runInput state =
        def runOutput = run job runInput
        def final _ = post (Pair runOutput state)
        # Don't run any 'post' steps until the Job has stopped running
        waitJobMerged final job
  Runner name score doit

global data Persistence =
  ReRun	# Job should be re-executed on every runJob call
  Once	# Job should only be run once in a given wake execution
  Keep	# Job should output be reusable between wake invocations
  Share	# Job should output be shared between workspaces

# A Plan describes a not-yet-executed Job
tuple Plan =
  global Command:       List String  # The command-line arguments (the first is the command to run)
  global Visible:       List Path    # Only these files should be available to the command
  global Environment:   List String  # KEY=VALUE environment variables fed to the command
  global Directory:     String       # The directory in which the command should be run
  global StandardInput: String       # The file to which standard input should be connected
  global Persistence:   Persistence  # See Persistence table above
  global LocalOnly:     Boolean      # Must run directly in the local workspace; no output detection performed
  global Resources:     List String  # The resources a runner must provide to the job (licenses/etc)
  global RunnerFilter:  Runner => Boolean # Reject from consideration Runners which the Plan deems inappropriate
  global FnInputs:      (List String => List String) # Modify the Runner's reported inputs  (files read)
  global FnOutputs:     (List String => List String) # Modify the Runner's reported outputs (files created)
  global FnIndexes:     (List String => List String) # Modify the Runner's reported indexes (directories listed)
  Pool:                 Integer      # Resource pool used to pay for the Job

def isOnce = match _
  ReRun = False
  _     = True
def isKeep = match _
  ReRun = False
  Once  = False
  _     = True
def isShare = match _
  Share = True
  _     = False

# Convenience accessor methods
global def getPlanOnce  p = isOnce  (getPlanPersistence p)
global def getPlanKeep  p = isKeep  (getPlanPersistence p)
global def getPlanShare p = isShare (getPlanPersistence p)

global def setPlanOnce  v p = editPlanOnce  (\_ v) p
global def setPlanKeep  v p = editPlanKeep  (\_ v) p
global def setPlanShare v p = editPlanShare (\_ v) p

# Helper methods that maintain the invariant that: Share => Keep => Once
global def editPlanOnce f =
  def helper = match _
    ReRun if   f False = Once
    Once  if ! f True  = ReRun
    Keep  if ! f True  = ReRun
    Share if ! f True  = ReRun
    x                  = x
  editPlanPersistence helper _

global def editPlanKeep f =
  def helper = match _
    ReRun if   f False = Keep
    Once  if   f False = Keep
    Keep  if ! f True  = Once
    Share if ! f True  = Once
    x                  = x
  editPlanPersistence helper _

global def editPlanShare f =
  def helper = match _
    ReRun if   f False = Share
    Once  if   f False = Share
    Keep  if   f False = Share
    Share if ! f True  = Keep
    x                  = x
  editPlanPersistence helper _

# The criteria which determine if Job execution can be skipped:
#   Once  is True and a matching job was run by this wake invocation
#   Keep  is True and there is matching output in the workspace
#   Share is True and there is matching output in a shared cache
# A Job is considered matching if:
#   The Command, Environment, Directory, and StandardInput are exact matches
#   FnInputs, FnOutputs, FnIndexes have the same hashcode
# Output is considered matching if:
#   The prior Outputs exist as the output of a matching Job
#   The prior Inputs have the same hashes as files in the workspace
#   The prior Indexes observe the same set of Visible files

# Set reasonable defaults for all Plan arguments
def id x = x
global def makePlan cmd visible =
  Plan cmd visible environment "." "" Share False Nil (\_ True) id id id 1

global def makeManualPlan cmd visible foutputs =
  Plan cmd visible environment "." "" Share True Nil (\_ True) id (\_ foutputs Unit) id 1

def makeRawPlan cmd  =
  Plan cmd Nil Nil "." "" ReRun True Nil (\_ True) id id id 1

def defaultUsage = Usage 0 0.0 0.0 0 0 0

# This runner does not detect inputs/outputs/indexes on it's own
# You must use Fn{Inputs,Outputs,Indexes} to fill in this information
global def manualRunner =
  def launch job pool dir stdin env cmd status runtime cputime membytes ibytes obytes = prim "job_launch"
  def doit job input =
   # Ensure that match does not re-raise the exception (launch must run)
   match (try (\_ RunnerInput (cast input) Nil Nil "" "" Nil "" None 0) input)
     RunnerInput cmd vis env dir stdin _ _ predict pool =
       match (getOrElse defaultUsage (try (\_ None) predict))
         Usage status runtime cputime mem in out =
           def _ = launch job pool dir stdin env.implode cmd.implode status runtime cputime mem in out
           RunnerOutput (map getPathName vis) Nil Nil (getJobReality job)
  def score (Plan _ _ _ _ _ _ lo res _ _ _ _ _) = match res
    Nil = if lo then 1.0 else raise "manual: cannot detect outputs"
    _   = raise "manual: cannot supply resources"
  Runner "manual" score doit

global def virtualRunner =
  def virtual job stdout stderr status runtime cputime membytes ibytes obytes = prim "job_virtual"
  def doit job input =
   # Ensure that match does not re-raise the exception (virtual must run)
   match (try (\_ RunnerInput (cast input) Nil Nil "" "" Nil "" None 0) input)
     RunnerInput cmd vis env dir stdin _ _ predict pool =
       match (getOrElse defaultUsage (try (\_ None) predict))
         Usage status runtime cputime mem in out =
           # Make sure any exceptions get fed into virtual
           def stuff = implode (dir, stdin, str pool, cmd ++ env)
           def s = if stuff ==* "" then status else status
           def _ = virtual job "" "" s runtime cputime mem in out # sets predict+reality
           RunnerOutput (map getPathName vis) Nil Nil (getJobReality job)
  Runner "virtual" (\_ 0.0) doit

def pid = prim "pid"

def implode l = cat (foldr (_, "\0", _) Nil l)
def runAlways cmd env dir stdin res finputs foutputs findexes vis keep run pool =
  def create dir stdin env cmd visible keep = prim "job_create"
  def finish job inputs outputs status runtime cputime membytes ibytes obytes = prim "job_finish"
  def cache dir stdin env cmd visible = prim "job_cache"
  def build _ =
    def doit job =
      def prefix = "{str pid}.{str (getJobId job)}"
      def usage = getJobRecord job
      def output = run job (RunnerInput cmd vis env dir stdin res prefix usage pool)
      def final _ =
        # Make sure we run finish even if the runner raises an exception
        match (try (\_ RunnerOutput (cast output) (cast output) (cast output) (cast output)) output)
          RunnerOutput inputs outputs indexes usage =
            match (try (\_ defaultUsage) usage)
              Usage status runtime cputime mem in out =
                def input  = finputs  inputs  | map simplify | implode
                def output = foutputs outputs | map addhash  | implode
                finish job input output status runtime cputime mem in out
      # Make sure we don't hash files before the job has stopped running
      def _ = waitJobMerged final job
      job
    # Do not invoke the runner/finish if job create fails
    def rawjob = create dir stdin env.implode cmd.implode (map getPathName vis).implode (if keep then 1 else 0)
    reraise rawjob doit
  def confirm last job =
    def notOk (Pair name hash) = hashcode name !=* hash
    match (waitJobMerged (\_ find notOk last) job)
      None = job
      Some (Pair (Pair file saw) _) =
        raise "Hash mismatch for {file} ({saw} != {hashcode file}); remove it"
  match keep
    False = build 0
    True  = match (cache dir stdin env.implode cmd.implode (map getPathName vis).implode)
      Pair (job, _) last = confirm last job
      Pair Nil      last = confirm last (build 0)

# Only run if the first four arguments differ
def runOnce cmd env dir stdin res finputs foutputs findexes vis keep run pool =
  memoize 9 (runAlways cmd env dir stdin res finputs foutputs findexes vis keep run pool)

# Default runners provided by wake
publish runner = manualRunner, fuseRunner, Nil

def runJobImp cmd env dir stdin res finputs foutputs findexes vis pers run pool =
  if isOnce pers
  then (runOnce   cmd env dir stdin res finputs foutputs findexes vis (isKeep pers) _ pool) | reraise run
  else (runAlways cmd env dir stdin res finputs foutputs findexes vis (isKeep pers) _ pool) | reraise run

global def runJobWith (Runner _ _ run) (Plan cmd vis env dir stdin pers _ res _ finputs foutputs findexes pool) =
  runJobImp cmd env dir stdin res finputs foutputs findexes vis pers run pool

data RunnerOption =
  Accept (score: Double) (runnerFn: Job => RunnerInput => RunnerOutput)
  Reject (why: String)

# Run the job!
global def runJob p = match p
  Plan cmd vis env dir stdin pers lo res rf finputs foutputs findexes pool =
    # Transform the 'List Runner' into 'List RunnerOption' with no exceptions
    def qualify runner =
      def accept = match runner
        Runner name scorefn fn =
          def score = match (rf runner)
            False = raise "{name}: rejected by Plan"
            True  =
              def score = scorefn p
              if score <=. 0.0 then raise "{name}: non-positive score" else score
          (Accept _ _) | reraise score | reraise fn
      try (Reject _.head) accept
    def best acc = match _ acc
      (Reject _) _ = acc
      (Accept score fn) (Pair bests bestr) =
        if score >. bests then Pair score (Some fn) else acc
    def opts = subscribe runner | map qualify
    match (opts | foldl best (Pair 0.0 None) | getPairSecond)
      Some r = runJobImp cmd env dir stdin res finputs foutputs findexes vis pers r pool
      None = raise "No runner available: {map format opts | catWith ", "}"

def toUsage (Pair (Pair status runtime) (Pair (Pair cputime membytes) (Pair ibytes obytes))) =
  Usage status runtime cputime membytes ibytes obytes

def getJobReality =
  def raw job = prim "job_reality"
  raw _ | toUsage

def waitJobMerged f j =
  def raw job = prim "job_reality"
  raw j | waitOne f

# Actual usage of a finished job
global def getJobReport =
  def raw job = prim "job_report"
  raw _ | toUsage

# From database, available the moment a Job exists
global def getJobRecord =
  def raw job = prim "job_record"
  raw _ | atOpt 0 | omap toUsage

# Control a running/finished Job
def stdio job fd  = prim "job_output" # 1=stdout, 2=stderr; blocks till closed
def tree  job typ = prim "job_tree"   # 0=visible, 1=input, 2=output; blocks till finished
def fail job ok = if job.getJobStatus == 0 then ok else raise "Non-zero exit status ({str job.getJobStatus})"
global def killJob job signal = prim "job_kill" # s != 0 => kills; blocks till exit; return status
global def getJobStatus  job = getJobReport job | getUsageStatus
global def getJobStdout  job = stdio job 1
global def getJobStderr  job = stdio job 2
global def getJobInputs  job = fail job job.getJobFailedInputs
global def getJobOutputs job = fail job job.getJobFailedOutputs
global def getJobFailedInputs  job = tree job 1 | map getPairFirst | map Path
global def getJobFailedOutputs job = tree job 2 | map getPairFirst | map Path
global def getJobId job = prim "job_id"
global def getJobOutput = match _.getJobOutputs
  x, Nil = x
  Nil    = raise "no outputs available"
  _      = raise "more than one output found"

# Implement FUSE-based Runner
def wakePath = prim "execpath" # location of the wake executable
def fusePath = relative workspace (simplify "{wakePath}/../lib/wake/fuse-wake")
global def fuseRunner =
  def pre input =
    def mkdir mode path = prim "mkdir"
    def write mode path content = prim "write"
    def visibleFile =
      (input.getRunnerInputDirectory, input.getRunnerInputVisible | map getPathName) | implode
      | write 0664 "{mkdir 0775 '.build'}/{input.getRunnerInputPrefix}.visible"
    def cmd = fusePath, visibleFile, Nil
    def fuse = makeRawPlan cmd | setPlanPool 0 | runJobWith manualRunner
    def handle _ = raise "Could not start fuse-wake ({str fuse.getJobStatus}): {fuse.getJobStderr | tokenize "\n" | head}"
    def root = try handle (extract 'OK: (.*)' fuse.getJobStderr)
    Pair (editRunnerInputDirectory ("{root.head}/{_}") input) fuse
  def post (Pair output fuse) =
    def _ = killJob fuse 14 # SIGALRM
    def result = extract "(.*\0)?\0(.*)" fuse.getJobStdout
    def inputs  = result | at 0 | tokenize "\0" | filter (_!=*"")
    def outputs = result | at 1 | tokenize "\0" | filter (_!=*"")
    def usage (Usage ps pr pc pm pi po) = match fuse.getJobReport
      Usage fs _ fc fm fi fo =
        Usage (if fs == 0 then ps else fs) pr (fc +. pc) (fm + pm) (fi + pi) (fo + po)
    output
    | setRunnerOutputInputs  inputs
    | setRunnerOutputOutputs outputs
    | editRunnerOutputUsage usage
  def score (Plan _ _ _ _ _ _ lo res _ _ _ _ _) = match res
    Nil = if lo then raise "fuse: would hide workspace" else 1.0
    _   = raise "fuse: cannot supply resources"
  makeRunner "fuse" score pre post manualRunner

# Make a Runner that runs a named script to run jobs
# score: Plan => Double; runJob chooses the runner with the largest score for a Plan
# estimate: Usage => Option Usage; predict local usage based on prior recorded usage
global def makeJSONRunner script score estimate =
  def pre (RunnerInput command visible environment directory stdin res prefix record _) =
    def json = JObject (
      "command"     → command     | map JString | JArray,
      "environment" → environment | map JString | JArray,
      "visible"     → visible | map (_.getPathName.JString) | JArray,
      "directory"   → JString directory,
      "stdin"       → JString stdin,
      "resources"   → res | map JString | JArray,
      "version"     → JString version,
      match record
        None = Nil
        Some (Usage status runtime cputime membytes inbytes outbytes) =
          "usage" → JObject (
            "status"   → JInteger status,
            "runtime"  → JDouble  runtime,
            "cputime"  → JDouble  cputime,
            "membytes" → JInteger membytes,
            "inbytes"  → JInteger inbytes,
            "outbytes" → JInteger outbytes,
            Nil
          ), Nil
    )
    def mkdir mode path = prim "mkdir"
    def write mode path content = prim "write"
    def inFile = prettyJSON json | write 0664 "{mkdir 0775 '.build'}/{prefix}.in.json"
    def outFile = ".build/{prefix}.out.json"
    def cmd = script.getPathName, inFile, outFile, Nil
    def proxy = RunnerInput cmd Nil environment "." "" Nil prefix (omapPartial estimate record) 1
    Pair proxy outFile
  def post (Pair output outFile) =
    def content = parseJSONFile outFile
    def usage = content // "usage"
    def usageOut =
      Usage
      (usage // "status"   | getJInteger | getOrElse 255)
      (usage // "runtime"  | getJDouble  | getOrElse 0.0)
      (usage // "cputime"  | getJDouble  | getOrElse 0.0)
      (usage // "membytes" | getJInteger | getOrElse 0)
      (usage // "inbytes"  | getJInteger | getOrElse 0)
      (usage // "outbytes" | getJInteger | getOrElse 0)
    def getK str = content // str | getJArray | getOrElse Nil | mapPartial getJString
    RunnerOutput (getK "inputs") (getK "outputs") (getK "indexes") usageOut
  makeRunner "json-{script.getPathName}" score pre post manualRunner

global def executeJSON json =
  def makeVirtual visible =
    def add f h = prim "add_hash"
    Path (add visible "0")
  def cmd   = json // "command"     | getJArray  | getOrElse Nil | mapPartial getJString
  def vis   = json // "visible"     | getJArray  | getOrElse Nil | mapPartial getJString | map makeVirtual
  def env   = json // "environment" | getJArray  | getOrElse Nil | mapPartial getJString
  def dir   = json // "directory"   | getJString | getOrElse "."
  def stdin = json // "stdin"       | getJString | getOrElse ""
  # Resources should have been resolved by the runner prior to invocation by us
  def res   = Nil # json // "resources"   | getJString | getOrElse Nil | mapPartial getJString
  def job = Plan cmd vis env dir stdin ReRun True res (\_ True) id id id 1 | runJobWith fuseRunner
  JObject (
    "inputs"  → tree job 1 | map (_.getPairFirst.JString) | JArray,
    "outputs" → tree job 2 | map (_.getPairFirst.JString) | JArray,
    match job.getJobReport
      Usage status runtime cputime membytes inbytes outbytes =
        "usage" → JObject (
          "status"   → JInteger status,
          "runtime"  → JDouble runtime,
          "cputime"  → JDouble cputime,
          "membytes" → JInteger membytes,
          "inbytes"  → JInteger inbytes,
          "outbytes" → JInteger outbytes,
          Nil
        ), Nil
  )

# Paths differ from Strings in that they have been hashed; their content is frozen
data Path = Path String
global def getPathName (Path name) = name
global def getPathParent (Path name) = Path (simplify "{name}/..")

def addhash f =
  def p = simplify f
  def add f h = prim "add_hash"
  add p (hashcode p)

def hashcode f = memoize 0 (
  def get f = prim "get_hash"
  def reuse = get f
  if reuse !=* "" then reuse else
    def job = makeRawPlan ("<hash>", f, Nil) | runJobWith manualRunner
    if job.getJobStatus == 0
    then extract '(.{64}).*' job.getJobStdout | head
    else raise "Failed to hash file {f}"
)

def stateRunner =
  def add f h = prim "add_hash"
  def hash = "0000000000000000000000000000000000000000000000000000000000000000"
  def pre input =
    match input.getRunnerInputCommand
      _, file, Nil = Pair input file
      _ = raise "stateRunner: invalid command-line"
  def post (Pair output file) =
    editRunnerOutputOutputs (add file hash, _) output
  makeRunner "state" (\_ 0.0) pre post virtualRunner

# Mark a file whose contents must not be tracked
global def makeStatePath file =
  makePlan ("<state>", file, Nil) Nil
  | setPlanKeep        False
  | setPlanEnvironment Nil
  | setPlanFnOutputs   (file, _)
  | runJobWith stateRunner
  | getJobOutput

# Whenever possible, use 'job' if:
#   cmd can run under FUSE
#   cmd guarantees to produce the same outputs given the same inputs
# Examples:
#   gcc
# job only allows cmd access to 'visible', to prevent undeclared dependencies.
# If you miss declared visible inputs, your build will fail so you can fix it.
# If you declare too many visible inputs, cmd execution/replay will wait for unnecessary files.
global def job cmd visible =
  makePlan cmd visible
  | runJob

# Use alwaysJob when:
#   cmd can run under FUSE
#   cmd output can differ between invocations
# Examples:
#   date
# alwaysJob only allows cmd access to 'visible', to prevent undeclared dependencies.
# If you miss declared visible inputs, your build will fail so you can fix it.
# If you declare too many visible inputs, cmd execution/replay will wait for unnecessary files.
global def alwaysJob cmd visible =
  makePlan cmd visible
  | setPlanKeep False
  | runJob

# Use manualJob when:
#   cmd cannot run under FUSE, but you know which inputs and outputs cmd uses
#   cmd guarantees to produce the same outputs given the same inputs
# Examples:
#   vcs
# cmd will have access to the entire workspace.
# manualJob behaves like normal target rule in a Makefile.
# If you miss declared visible inputs, your build is not reproducible and may run in the wrong order.
# If you declare too many visible inputs, cmd may be rerun and wait unnecessarily.
# If you miss declared outputs, dependant commands might fail or not run reproducibly.
# If you declare too many outputs, the build will fail.
global def manualJob cmd visible foutputs =
  makeManualPlan cmd visible foutputs
  | runJob

# Use volatileJob when:
#   cmd cannot run under FUSE, but you know which inputs and outputs cmd uses
#   cmd output can differ between invocations
# Examples:
#   ???
# volatileJob behaves like a PHONY target in a Makefile.
# If you miss declared visible inputs, your build is not reproducible and may run in the wrong order.
# If you declare too many visible inputs, cmd may wait unnecessarily.
# If you miss declared outputs, dependant commands might fail or not run reproducibly.
# If you declare too many outputs, the build will fail.
global def volatileJob cmd visible foutputs =
  makeManualPlan cmd visible foutputs
  | setPlanKeep False
  | runJob
