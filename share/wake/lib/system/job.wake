# The internal function operates on imploded strings, not lists
def primjob pool root dir stdin env cmd = prim "job_launch"
def primcache dir stdin env cmd visible = prim "job_cache"

def implode l = cat (foldr (_, "\0", _) Nil l)
global def jobcache build dir stdin env cmd visible = memoize 0 (
  match (tryelse (\_ None) (Some _) (primcache dir stdin env.implode cmd.implode visible.implode))
    None     = build 0
    Some out =
      def notOk pair = hashcode pair.first !=* pair.second
      match (find notOk out.outputs)
        None = out
        Some (Pair (Pair file saw) _) =
          def expect = hashcode file
          raise "Hash mismatch for {file} ({saw} != {expect}); remove it or run with -f"
)

# Launch a job, raw interface
# If you use this API, you MUST also run 'finish' on the result AFTER status is available
#   root:  fake root directory
#   dir:   directory where the command should be run
#   stdin: file to attach to standard input ("" = nothing)
#   env:   string list of all environement variables in the form key=value
#   cmd:   string list of command arguments (head is the full path to the command)
global def launch root dir stdin env cmd = primjob 1 root dir stdin env.implode cmd.implode

def fail job ok =
  if job.status == 0 then ok else
    raise "Non-zero exit status ({str job.status})"

# Access the output of a job
def stdio job fd  = prim "job_output" # 1=stdout, 2=stderr; blocks till closed
def tree  job typ = prim "job_tree"   # 0=visible, 1=input, 2=output; blocks till finished
global def kill    job signal = prim "job_kill" # s != 0 => kills; blocks till exit; return status
global def status  job = kill  job 0
global def stdout  job = stdio job 1
global def stderr  job = stdio job 2
global def inputs  job = fail job (tree job 1)
global def outputs job = fail job (tree job 2)
global def rawinputs  job = tree job 1
global def rawoutputs job = tree job 2
global def output  job =
  def got = outputs job
  def num = got.len
  if      num == 1 then got.head.first
  else if num == 0 then raise "no outputs available"
  else                  raise "more than one output found"

# Complete a job, marking done and recording used inputs/outputs
global def finish job inputs outputs =
  def imp job inputs outputs = prim "job_finish" # ignored except on first call; blocks till exit; returns true
  imp job inputs.implode outputs.implode

global def hashpair f = memoize 0 ( # Pair file hash
  def job = launch "." "." "" Nil ("<hash>", f, Nil)
  def final _ = finish job Nil Nil
  def _ = waitOne final job.status
  def add f h = prim "add_hash"
  if job.status == 0 then add f (head (extract '(.{32}).*' job.stdout)) else raise "Hashing failed"
)
global def hashname f = (hashpair f).first  # just the filename
global def hashcode f = (hashpair f).second # just the hashcode

# A job where all inputs and outputs are known a-priori
global def uncached_manual_job dir stdin env cmd inputs foutputs = memoize 1 (
  def job = launch "." dir stdin env cmd
  def final _ = finish job (map hashname inputs) (map hashname (foutputs Unit))
  def _ = waitOne final job.status
  job
)

global def cached_manual_job dir stdin env cmd inputs foutputs =
  def build _ = uncached_manual_job dir stdin env cmd inputs foutputs
  jobcache build dir stdin env cmd (map hashname inputs)

# Location of wake itself
def wakepath = prim "execpath"

# Still not caching, just hermetic
def fusepath = relative workspace (simplify "{wakepath}/../lib/wake/fuse-wake")
global def uncached_fuse_job dir stdin env cmd files = memoize 0 (
  def visible = dir, map hashname files
  def doit args =
    def fuse = primjob 0 "." "." "" "" args
    def endfuse _ = finish fuse Nil Nil
    def _ = waitOne endfuse fuse.status
    def err = fuse.stderr
    def handle _ = raise "Could not start fuse-wake: {err}"
    def list = try handle (extract 'OK: (.*)' err)
    def job = launch list.head dir stdin env cmd
    def final _ = # run once job exits
      def status = kill fuse 14 # SIGALRM
      def result = extract "(.*\0)?\0(.*)" fuse.stdout
      def inputs = (tokenize "\0" (at 0 result)).reverse.tail
      def outputs = (tokenize "\0" (at 1 result)).reverse.tail
      finish job inputs (map hashname outputs)
    def _ = waitOne final job.status
    job
  tryelse (raise _.cat) doit (fusepath, visible).implode
)

global def cached_fuse_job dir stdin env cmd files =
  def build _ = uncached_fuse_job dir stdin env cmd files
  jobcache build dir stdin env cmd (map hashname files)

# Most jobs don't need explicit stdin/env control
global def environment = subscribe environment

# Whenever possible, use 'job' if:
#   cmd can run under FUSE
#   cmd guarantees to produce the same outputs given the same inputs
# Examples:
#   gcc
# job only allows cmd access to 'inputs', to prevent undeclared dependencies.
# If you miss declared inputs, your build will fail so you can fix it.
# If you declare too many inputs, cmd execution/replay will wait for unnecessary files.
global def job cmd inputs = cached_fuse_job "." "" environment cmd inputs

# Use always_job when:
#   cmd can run under FUSE
#   cmd output can differ between invocations
# Examples:
#   date
# always_job only allows cmd access to 'inputs', to prevent undeclared dependencies.
# If you miss declared inputs, your build will fail so you can fix it.
# If you declare too many inputs, cmd execution/replay will wait for unnecessary files.
global def always_job cmd inputs = uncached_fuse_job "." "" environment cmd inputs

# Use manual_job when:
#   cmd cannot run under FUSE, but you know which inputs and outputs cmd uses
#   cmd guarantees to produce the same outputs given the same inputs
# Examples:
#   vcs
# cmd will have access to the entire workspace.
# manual_job behaves like normal target rule in a Makefile.
# If you miss declared inputs, your build is not reproducible and may run in the wrong order.
# If you declare too many inputs, cmd may be rerun and wait unnecessarily.
# If you miss declared outputs, dependant commands might fail or not run reproducibly.
# If you declare too many outputs, the build will fail.
global def manual_job cmd inputs foutputs = cached_manual_job "." "" environment cmd inputs foutputs

# Use volatile_job when:
#   cmd cannot run under FUSE, but you know which inputs and outputs cmd uses
#   cmd output can differ between invocations
# Examples:
#   ???
# volatile_job behaves like a PHONY target in a Makefile.
# If you miss declared inputs, your build is not reproducible and may run in the wrong order.
# If you declare too many inputs, cmd may wait unnecessarily.
# If you miss declared outputs, dependant commands might fail or not run reproducibly.
# If you declare too many outputs, the build will fail.
global def volatile_job cmd inputs foutputs = uncached_manual_job "." "" environment cmd inputs foutputs
