# Copyright 2024 SiFive, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You should have received a copy of LICENSE.Apache2 along with
# this software. If not, you may obtain a copy at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

package remote_cache

from http import _
from wake import _

# RSC Policy on engaging with the cache. Can be configured to only push to the cache, only pull from
# the cache, or both. Pushing requires an authorization key.
export data RemoteCachePolicy =
    RemoteCachePolicyPullOnly
    RemoteCachePolicyPushPull String
    RemoteCachePolicyPushOnly String

# Configuration details required to connect to the remote shared cache.
export tuple RemoteCacheApi =
    # The domain or ip address of the cache
    export Domain: String
    # The port serving the cache
    export Port: Integer
    # The remote cache policy, certain policies require authorization
    export Policy: RemoteCachePolicy
    # The total time (in seconds) that requests to the cache are allowed to take, from start to finish
    export MaxTime: Option Integer
    # The maximum time (in seconds) that requests to the cache will wait to establish a network connection
    export ConnectTime: Option Integer

## --- POST /job/matching types ---

# A request to the remote server to check if a job is cached
tuple CacheSearchRequest =
    # The label for the job. Not part of the key, used only for inspection
    Label: String
    # The command line of the job
    Cmd: List String
    # The directory of the job
    Cwd: String
    # The environment of the job
    Env: List String
    # User provided string to mark two jobs as different even if wake considers them the same
    HiddenInfo: String
    # If the job was ran as if a user was running it from a terminal
    IsAtty: Boolean
    # The stdin of the job
    Stdin: String
    # The list of files the job is allowed to read in the sandbox
    VisibleFiles: List Path

# A downloadable blob returned from the remote shared cache
tuple CacheSearchBlob =
    # The id of the blob on the remote server
    Id: String
    # The uri where the blob may be downloaded from. Not guaranteed to be http/https
    Uri: String

# A file backed by a blob that a cached job created
tuple CacheSearchOutputFile =
    # The path on disk of the file
    Path: String
    # The mode on disk of the file
    Mode: Integer
    # The description of how to download the files contents
    Blob: CacheSearchBlob

# A directory created by a cached job
tuple CacheSearchOutputDirectory =
    # The path on disk of the directory
    Path: String
    # The mode on disk of the directory
    Mode: Integer
    # If the directory is hidden or published to downstream users
    Hidden: Boolean

# A symlink created by a cached job
tuple CacheSearchOutputSymlink =
    # The path on disk of the symlink
    Path: String
    # The file being linked to
    Link: String

# A match response from the server. Specifies all details of a cached job
tuple CacheSearchResponseMatch =
    # The symlinks that were output by the job
    OutputSymlinks: List CacheSearchOutputSymlink
    # The directories that were output by the job
    OutputDirs: List CacheSearchOutputDirectory
    # The files that were output by the job
    OutputFiles: List CacheSearchOutputFile
    # The stdout of the job
    StdoutBlob: CacheSearchBlob
    # The stderr of the job
    StderrBlob: CacheSearchBlob
    # The code that the job return on exit
    Status: Integer
    # The total runtime of the job
    Runtime: Double
    # The total cputime of the job
    Cputime: Double
    # The total memory of the job
    Memory: Integer
    # The number of bytes read by the job
    IBytes: Integer
    # The number of bytes written by the job
    OBytes: Integer

# A response from the server to a CacheSearchRequest
data CacheSearchResponse =
    # The job was not found on the remote server
    NoMatch
    # The job was found on the remote server
    Match CacheSearchResponseMatch

## --- POST /job types ---

# A file created by a job and uploaded to the server as a blob
tuple CachePostRequestOutputFile =
    # The path on disk of the file
    Path: String
    # The mode on disk of the file
    Mode: Integer
    # The blob id returned by the server from the blob upload
    BlobId: String

# A directory created by a job
tuple CachePostRequestOutputDirectory =
    # The path on disk of the directory
    Path: String
    # The mode on disk of the directory
    Mode: Integer
    # If the directory is hidden or published to downstream users
    Hidden: Boolean

# A symlink created by a job
tuple CachePostRequestOutputSymlink =
    # The path on disk of the symlink
    Path: String
    # The file being linked to
    Link: String

# A request to the remote server to cache a job
tuple CachePostRequest =
    # The label for the job. Not part of the key, used only for inspection
    Label: String
    # The command line of the job
    Cmd: List String
    # The directory of the job
    Cwd: String
    # The environment of the job
    Env: List String
    # User provided string to mark two jobs as different even if wake considers them the same
    HiddenInfo: String
    # If the job was ran as if a user was running it from a terminal
    IsAtty: Boolean
    # The stdin of the job
    Stdin: String
    # The list of files the job is allowed to read in the sandbox
    VisibleFiles: List Path
    # The directories that were output by the job
    OutputDirs: List CachePostRequestOutputDirectory
    # The symlinks that were output by the job
    OutputSymlinks: List CachePostRequestOutputSymlink
    # The files that were output by the job
    OutputFiles: List CachePostRequestOutputFile
    # The blob id returned from the server for the stdout of the job
    StdoutBlobId: String
    # The blob id returned from the server for the stderr of the job
    StderrBlobId: String
    # The code that the job return on exit
    Status: Integer
    # The total runtime of the job
    Runtime: Double
    # The total cputime of the job
    Cputime: Double
    # The total memory of the job
    Memory: Integer
    # The number of bytes read by the job
    IBytes: Integer
    # The number of bytes written by the job
    OBytes: Integer

# A request to the remote server to check if a job is allowed to be cached
tuple CacheAllowedRequest =
    # The label for the job. Not part of the key, used only for inspection
    Label: String
    # The command line of the job
    Cmd: List String
    # The directory of the job
    Cwd: String
    # The environment of the job
    Env: List String
    # User provided string to mark two jobs as different even if wake considers them the same
    HiddenInfo: String
    # If the job was ran as if a user was running it from a terminal
    IsAtty: Boolean
    # The stdin of the job
    Stdin: String
    # The list of files the job is allowed to read in the sandbox
    VisibleFiles: List Path
    # The code that the job return on exit
    Status: Integer
    # The total runtime of the job
    Runtime: Double
    # The total cputime of the job
    Cputime: Double
    # The total memory of the job
    Memory: Integer
    # The number of bytes written by the job
    OBytes: Integer

# getRemoteCacheApiAuthorization: Extracts the auth string from RemoteCacheApi if present
#
# ```
# api.getRemoteCacheApiAuthorization = Some "myauth"
# api.getRemoteCacheApiAuthorization = None
# ```
export def getRemoteCacheApiAuthorization (api: RemoteCacheApi): Option String =
    match (api.getRemoteCacheApiPolicy)
        RemoteCachePolicyPullOnly -> None
        RemoteCachePolicyPushOnly auth -> Some auth
        RemoteCachePolicyPushPull auth -> Some auth

# getRemoteCacheApiCanPush: Determines if the api is configured for pushing to the cache
#
# ```
# api.getRemoteCacheApiCanPush = True
# ```
export def getRemoteCacheApiCanPush (api: RemoteCacheApi): Boolean =
    match (api.getRemoteCacheApiPolicy)
        RemoteCachePolicyPullOnly -> False
        RemoteCachePolicyPushOnly _ -> True
        RemoteCachePolicyPushPull _ -> True

# getRemoteCacheApiCanPull: Determines if the api is configured for pulling from the cache
#
# ```
# api.getRemoteCacheApiCanPull = True
# ```
export def getRemoteCacheApiCanPull (api: RemoteCacheApi): Boolean =
    match (api.getRemoteCacheApiPolicy)
        RemoteCachePolicyPullOnly -> True
        RemoteCachePolicyPushOnly _ -> False
        RemoteCachePolicyPushPull _ -> True

# makeRemoteCacheApi: Parses config string into RemoteCacheApi
#
# ```
#  makeRemoteCacheApi "pushpull:local:1234:myauth:300:10" = Pass (RemoteCacheApi "local" 1234 (PushPull "myauth") (Some 300) (Some 10))
#  makeRemoteCacheApi "push:local:1234:myauth" = Pass (RemoteCacheApi "local" 1234 (Push "myauth") None None)
#  makeRemoteCacheApi "pull:local:1234:" = Pass (RemoteCacheApi "local" 1234 Pull None None)
#  makeRemoteCacheApi "pull:local:1234:myauth" = Pass (RemoteCacheApi "local" 1234 Pull None None)
#  makeRemoteCacheApi "push:local:1234" = Fail (...)
#  makeRemoteCacheApi "push:local" = Fail (...)
#  makeRemoteCacheApi "push:local:asdf:myauth" = Fail (...)
# ```
export def makeRemoteCacheApi (config: String): Result RemoteCacheApi Error =
    # split into at most 6 pieces, missing tail parts become ""
    def parts = (config | tokenize `:`) ++ ("", "", "", "", "", Nil)

    require (policyStr, domain, portStr, authStr, maxStr, connStr, _) = parts
    else
        unreachable
        "Remote cache config was set with incorrect format. Saw: '{config}'. Expected 'policy:domain:port:auth:maxTime:connTime' (auth, maxTime, connTime may be omitted)"

    require Some (port) =
        portStr
        | int
    else failWithError "Remote cache config was set with non-integer port. Saw: {portStr}"

    # Default maxTime to 300 and connTime to 10 if empty
    def maxT =
        int maxStr
        | getOrElse 300

    def connT =
        int connStr
        | getOrElse 10

    require Pass policy = match (policyStr; authStr)
        "pull"; _ -> Pass (RemoteCachePolicyPullOnly)
        "push"; "" -> failWithError "Policy 'push' requires authorization"
        "pushpull"; "" -> failWithError "Policy 'pushpull' requires authorization"
        "push"; auth -> Pass (RemoteCachePolicyPushOnly auth)
        "pushpull"; auth -> Pass (RemoteCachePolicyPushPull auth)
        p; _ -> failWithError "Policy '{p}' must be one of 'push', 'pull', 'pushpull'"

    def api = RemoteCacheApi domain port policy (Some maxT) (Some connT)

    # When in debug mode, allow server incompatible version.
    def overrideOnDebugCache check =
        require Fail err = check
        else check

        require True = shouldDebugRemoteCache Unit
        else check

        printlnLevel
        logWarning
        "RSC client is incompatable with server but continuing due to DEBUG enabled. Reason: {format err}"
        | Pass

    # If the client isn't compatiable with the server then give up on the cache
    require Pass Unit =
        api
        | rscApiCheckClientVersion "sifive/wake/{version}"
        | overrideOnDebugCache

    # If auth is not set we are done. Just return the api
    require Some _ = api.getRemoteCacheApiAuthorization
    else Pass api

    # Auth was set so it must be validated.
    api
    | rscApiCheckAuthorization
    | rmap (\_ api)

# rscApiPostStringBlob: Posts a named string as a blob to the remote server defined by *api*
#                       then returns the id associated to the blob. Requires authorization.
#
# ```
#  api | rscApiPostStringBlob "foo" "my foo contents" = Pass "asdf-fdsa-asdf-fdsa"
#  (RemoteCacheApi "foo" 1 None) | rscApiPostStringBlob "foo" "my foo contents" = Fail "authorization required"
# ```
export def rscApiPostStringBlob (name: String) (value: String) (api: RemoteCacheApi): Result String Error =
    require Pass _ = guardRemoteCacheDisabled Unit

    def contentType = contentTypeFromSize value.strlen

    require Pass temp = writeTempFile name value

    uploadBlobRequest api (addFormData name temp contentType)

# rscApiPostFileBlob: Posts a named file on disk to the remote server defined by *api*
#                     then returns the id associated to the blob. Requires authorization.
#
# ```
#  api | rscApiPostFileBlob "foo" "/some/path/to/foo" = Pass "asdf-fdsa-asdf-fdsa"
#  (RemoteCacheApi "foo" 1 None) | rscApiPostFileBlob "foo" "/some/path/to/foo" = Fail "authorization required"
# ```
export def rscApiPostFileBlob (name: String) (file: String) (api: RemoteCacheApi): Result String Error =
    require Pass _ = guardRemoteCacheDisabled Unit

    # We must use unsafe here since we cannot elevate *file* to a Path without either copying it
    # or triggering the 'job output by multiple files' error.

    def contentType = match (unsafe_stat file)
        Pass (Stat _ _ size) -> contentTypeFromSize size
        Fail _ -> None

    uploadBlobRequest api (unsafe_addFormData name file contentType)

# rscApiPostJob: Posts a job defined by *req* to the remote cache server. Requires authorization.
#
# ```
#  api | rscApiPostJob (CachePostRequest ...) = Pass Unit
#  (RemoteCacheApi "foo" 1 None) | rscApiPostJob (CachePostRequest ...) = Fail "authorization required"
# ```
export def rscApiPostJob (req: CachePostRequest) (api: RemoteCacheApi): Result Unit Error =
    require Pass _ = guardRemoteCacheDisabled Unit

    require Some auth = api.getRemoteCacheApiAuthorization
    else failWithError "rsc: RSC Client not configured for pushing to the server"

    def jsonStr =
        req
        | getCachePostRequestJson
        | formatJSON

    def _ =
        require True = shouldDebugRemoteCache Unit

        def _ =
            writeTempFile "remote.cache.api.postJob.req" "label: {req.getCachePostRequestLabel}\nreq: {jsonStr}"

        True

    require Pass response =
        makeRoute api "job"
        | buildHttpRequest
        | setMethod HttpMethodPost
        | addContentTypeJsonHeader
        | addAuthorizationHeader auth
        | setBody jsonStr
        | setTimeout api.getRemoteCacheApiMaxTime api.getRemoteCacheApiConnectTime
        | makeRequest
        | matchRequestResult req.getCachePostRequestLabel

    def _ =
        require True = shouldDebugRemoteCache Unit

        def _ =
            writeTempFile
            "remote.cache.api.postJob.res.{response.getHttpResponseStatusCode | format}"
            "label: {req.getCachePostRequestLabel}\nres: {response | format}"

        True

    require (Some 200) = response.getHttpResponseStatusCode
    else failWithError "rsc: post job failed with code {response.getHttpResponseStatusCode | format}"

    Pass Unit

# rscApiCheckJobAllowed: Checks if the remote server is willing to accept a completed job as
#                        described by *req*. If not then the job should not be posted.
#
# ```
#  api | rscApiCheckJobAllowed (CacheAllowedRequest ...) = Pass True
# ```
export def rscApiCheckJobAllowed (req: CacheAllowedRequest) (api: RemoteCacheApi): Result Boolean Error =
    require Pass _ = guardRemoteCacheDisabled Unit

    require True = api.getRemoteCacheApiCanPush
    else failWithError "rsc: RSC Client not configured for pushing to the server"

    def jsonStr =
        req
        | getCacheAllowedRequestJson
        | formatJSON

    def _ =
        require True = shouldDebugRemoteCache Unit

        def _ =
            writeTempFile
            "remote.cache.api.allowedJob.req"
            "label: {req.getCacheAllowedRequestLabel}\nreq: {jsonStr}"

        True

    require Pass response =
        makeRoute api "job/allowed"
        | buildHttpRequest
        | setMethod HttpMethodPost
        | addContentTypeJsonHeader
        | setBody jsonStr
        | setTimeout api.getRemoteCacheApiMaxTime api.getRemoteCacheApiConnectTime
        | makeRequest
        | matchRequestResult req.getCacheAllowedRequestLabel

    def _ =
        require True = shouldDebugRemoteCache Unit

        def _ =
            writeTempFile
            "remote.cache.api.allowedJob.res.{response.getHttpResponseStatusCode | format}"
            "label: {req.getCacheAllowedRequestLabel}\nres: {response | format}"

        True

    match response.getHttpResponseStatusCode
        # Allowed
        Some 200 -> Pass True
        # Denied due to job contents
        Some 406 -> Pass False
        # Denied because already cached
        Some 409 -> Pass False
        # Denied because server needs to shed load
        Some 429 -> Pass False
        # Allowed for unknown reason
        Some code if code > 199 && code < 300 -> Pass True
        # Denied for unknown reason
        Some _ -> Pass False
        # Failed to parse status code from request
        None -> failWithError "Missing status code from request"

# rscApiFindMatchingJob: Searches the remote server defined by *api* for a cached job that matches
#                        the job key provided by *req*. Returns a response that may or may not have
#                        the matching job. Does not require authorization.
#
# ```
#  api | rscApiFindMatchingJob (CacheSearchRequest ...) = Pass (CacheSearchResponse ...)
# ```
export def rscApiFindMatchingJob (req: CacheSearchRequest) (api: RemoteCacheApi): Result CacheSearchResponse Error =
    require Pass _ = guardRemoteCacheDisabled Unit

    require True = api.getRemoteCacheApiCanPull
    else failWithError "rsc: RSC Client not configured for pulling from the server"

    def jsonStr =
        req
        | getCacheSearchRequestJson
        | formatJSON

    def _ =
        require True = shouldDebugRemoteCache Unit

        def _ =
            writeTempFile
            "remote.cache.api.findJob.req"
            "label: {req.getCacheSearchRequestLabel}\nreq: {jsonStr}"

        True

    require Pass response =
        makeRoute api "job/matching"
        | buildHttpRequest
        | setMethod HttpMethodPost
        | addContentTypeJsonHeader
        | setBody jsonStr
        | setTimeout api.getRemoteCacheApiMaxTime api.getRemoteCacheApiConnectTime
        | makeRequest
        | matchRequestResult req.getCacheSearchRequestLabel

    def _ =
        require True = shouldDebugRemoteCache Unit

        def _ =
            writeTempFile
            "remote.cache.api.findJob.res.{response.getHttpResponseStatusCode | format}"
            "label: {req.getCacheSearchRequestLabel}\nres: {response | format}"

        True

    require Pass json =
        response.getHttpResponseBody.parseJSONBody
        | addErrorContext "rsc: http body contains invalid JSON"

    mkCacheSearchResponse json

# rscApiCheckClientVersion: Checks if the client version is compatiable with the server.
#
# ```
#  api | rscApiCheckClientVersion "sifive/wake/1.2.3 = Pass Unit
# ```
export target rscApiCheckClientVersion (version: String) (api: RemoteCacheApi): Result Unit Error =
    require Pass _ = guardRemoteCacheDisabled Unit

    require Pass response =
        makeRoute api "version/check?version={version}"
        | buildHttpRequest
        | setMethod HttpMethodGet
        | setTimeout api.getRemoteCacheApiMaxTime api.getRemoteCacheApiConnectTime
        | makeRequest
        | matchRequestResult "version check"

    match response.getHttpResponseStatusCode
        Some 200 -> Pass Unit
        Some x -> failWithError "Incompatiable client. Status code: {str x}"
        None -> failWithError "Incompatiable client. Unable to determine status code"

# rscApiCheckAuthorization: Checks if the provided authorization key is valid.
#
# ```
#  api | rscApiCheckAuthorization = Pass Unit
# ```
export target rscApiCheckAuthorization (api: RemoteCacheApi): Result Unit Error =
    require Pass _ = guardRemoteCacheDisabled Unit

    require Some auth = api.getRemoteCacheApiAuthorization
    else failWithError "rsc: Checking authorization requires authorization but none was provided"

    require Pass response =
        makeRoute api "auth/check"
        | buildHttpRequest
        | setMethod HttpMethodPost
        | addAuthorizationHeader auth
        | setTimeout api.getRemoteCacheApiMaxTime api.getRemoteCacheApiConnectTime
        | makeRequest
        | matchRequestResult "auth check"

    match response.getHttpResponseStatusCode
        Some 200 -> Pass Unit
        Some x -> failWithError "Invalid auth key. Status code: {str x}"
        None -> failWithError "Invalid auth key. Unable to determine status code"

# Converts db only blob uris into actual data
# maps path = "%46%6F%6F" to content = "foo"
def resolveDbScheme _scheme path =
    # If path is empty we have the empty string
    require True = path.strlen > 0
    else Pass ""

    # If not empty then it must as least be %00
    require True = path.strlen >= 3
    else failWithError "rsc: Invalid db path: '{path}'"

    require "", byteStrs = tokenize `%` path
    else failWithError "rsc: Failed to extract bytes from db path: '{path}'"

    require Some bytes =
        byteStrs
        | map (intbase 16)
        | findNone
    else failWithError "rsc: Failed to parse bytes strings into bytes from db path: '{path}'"

    bytes
    | map integerToByte
    | cat
    | Pass

# Dispatches the content resolution for uri based on its scheme
def resolveUriResponse (dbSchemeFn: (String => String => Result a Error)) (fileSchemeFn: (String => String => Result a Error)) (uri: String) =
    require scheme, path, Nil = extract `([a-zA-Z][a-zA-Z0-9+.-]*)://(.*)` uri
    else failWithError "rsc: uri has unexpected format: '{uri}'"

    def unsupportedSchemeFn s p =
        failWithError "rsc: scheme '{scheme}' from uri '{uri}' is not supported"

    def schemeFn = match scheme
        "db" -> dbSchemeFn
        "file" -> fileSchemeFn
        "http" -> fileSchemeFn
        "https" -> fileSchemeFn
        _ -> unsupportedSchemeFn

    schemeFn scheme path

# rscApiGetStringBlob: Downloads a blob and returns the contents as a string
#
# ```
#  rscApiGetStringBlob (RemoteCacheBlob "asdf" "https://...") = Pass "foo\nbar\nbat"
# ```
export def rscApiGetStringBlob ((CacheSearchBlob _ uri): CacheSearchBlob): Result String Error =
    def resolveStringFileScheme scheme path =
        buildHttpRequest "{scheme}://{path}"
        | setMethod HttpMethodGet
        | makeRequest
        |< getHttpResponseBody

    uri
    | resolveUriResponse resolveDbScheme resolveStringFileScheme

# rscApiGetFileBlob: Downloads a blob to *path* with *mode* permisssions and return *path*
#
# ```
#  rscApiGetFileBlob (RemoteCacheBlob "asdf" "https://...") "foo/bar" 0644 = Pass "foo/bar"
# ```
export def rscApiGetFileBlob ((CacheSearchBlob blobId uri): CacheSearchBlob) (path: String) (mode: Integer): Result String Error =
    def resolveDbSchemeToFile scheme path =
        resolveDbScheme scheme path
        |> writeTempFile "rsc.output_file.blob.{blobId}"

    def resolveBlobFileScheme scheme path =
        buildHttpRequest "{scheme}://{path}"
        | setMethod HttpMethodGet
        | makeBinaryRequest

    require Pass blobPath = (uri | resolveUriResponse resolveDbSchemeToFile resolveBlobFileScheme)

    def fixupScript =
        """
        # 1. No failures are acceptable
        set -e
        # 2. Remove the old rsctmp file if it exists
        rm -f '%{path}.rsctmp'
        # 3. Hardlink the file to not use 2x disk space
        cp -l %{blobPath.getPathName} '%{path}.rsctmp'
        # 4. Set the permissions as specified
        chmod %{mode | strOctal} '%{path}.rsctmp'
        # 5. If the file was previously created with the exact inode by the rsc but not cleaned up
        #    then it needs to be removed so we can complete the atomic mv
        [ '%{path}.rsctmp' -ef '%{path}' ] && rm '%{path}'
        # 6. Atomically move so interruptions don't effect the build.
        mv '%{path}.rsctmp' '%{path}'
        """

    def job =
        makeShellPlan fixupScript (blobPath, Nil)
        | setPlanLabel "rsc: fixup blob {path} from {blobPath.getPathName}"
        | setPlanPersistence Once
        # We need to copy the file over another jobs output space so:
        #   - We must run with the localRunner
        #   - We must lie and say we output nothing
        #   - The *path* must be listed as another jobs output to be available to the system
        | setPlanFnOutputs (\_ Nil)
        | runJobWith localRunner
        | setJobInspectVisibilityHidden

    require True = job.isJobOk
    else failWithError "Failed to cleanup downloaded file {path} from {blobPath.getPathName}"

    Pass path

# The temporary sentinel file used to disable the cache
export def disableCacheFilePath: String =
    ".build/tmp/disable_remote_cache"

def timeoutErrorMessage: String =
    "rsc: Remote cache disabled due to timeout"

def cascadeTimeoutErrorMessage: String =
    "rsc: Remote cache previously disabled due to timeout"

# Generates a UUID (using date in nano seconds) for the current wake invocation.
# This is used to verify and disable requests to the cache that are from the same invocation.
def generateUUID Unit: Result String Error =
    def uuidJob =
        makeExecPlan ("date", "+%s%N", Nil) Nil
        | setPlanLabel "rsc: generate client uuid"
        | setPlanPersistence Once # Exactly one UUID per wake invocation
        | runJobWith localRunner

    require True = isJobOk uuidJob
    else failWithError "failed to generate UUID for Wake invocation."

    uuidJob
    | getJobStdout

def disableRemoteCache Unit: Result Unit Error =
    require Pass uuid = generateUUID Unit
    require Pass _ = write disableCacheFilePath uuid

    Pass Unit

# This is only used to read temporary files that are purposefully not tracked by wake (i.e the sentinel disable cache file).
# This is used instead of the read function from io.wake as that takes in a Path.
def readTmpFile (pathStr: String): Result String Error =
    def imp p = prim "read"

    match (imp pathStr)
        Pass body -> Pass body
        Fail f -> Fail (makeError f)

export def guardRemoteCacheDisabled Unit: Result Unit Error =
    require Pass currentWakeUuid = generateUUID Unit

    def isRemoteCacheDisabled Unit = match (readTmpFile disableCacheFilePath)
        Pass writtenUuid -> writtenUuid ==* currentWakeUuid
        Fail _ -> False

    require False = isRemoteCacheDisabled Unit
    else failWithError cascadeTimeoutErrorMessage

    Pass Unit

## --- Helper functions ---

def contentTypeFromSize size =
    if size < 95 then Some "blob/small" else None

# TODO: Delete these once new json API is added to wake repo
def jField (jvalue: JValue) (key: String) =
    require JObject obj = jvalue
    else failWithError "not an object"

    require Some (Pair (Pair _ value) _) = find (_.getPairFirst ==~ key) obj
    else failWithError "key '{key}' not found"

    Pass value

# asBytesDelimedByNull ("a", "b", "cd",) = (15, 0, 16, 0, 17, 18, 0)
def asBytesDelimedByNull (parts: List String): List Integer =
    parts
    | map (\x unicodeToBytes x ++ (0,))
    | flatten

# getPathAsJson (Path "foo" "asdf") = (JObject ...)
def getPathAsJson path =
    JObject (
        "path" :-> JString path.getPathName,
        "hash" :-> JString path.getPathHash,
    )

# Helper function for further processing the result of a http request in relation to the rsc
def matchRequestResult (label: String) (attempt: Result HttpResponse Error): Result HttpResponse Error =
    match attempt
        Pass r -> Pass r
        Fail err ->
            def cause = err.getErrorCause

            if cause ==* "curl timed out (exit code 28)" then
                def _ = disableRemoteCache Unit
                def _ = breadcrumb "{label}: Disabling RSC due to timeout"
                def _ = printlnLevel logReport "RSC: Disabling rsc due to timeout"

                Fail (makeError timeoutErrorMessage)
            else
                Fail (makeError cause)

# Helper function for building the route for the resource
def makeRoute ((RemoteCacheApi domain port _ _ _)) (resource: String): String =
    "{domain}:{port | str}/{resource}"

# Helper function for uploading a blob.
def uploadBlobRequest (api: RemoteCacheApi) (setBlob: HttpRequest => HttpRequest): Result String Error =
    require Pass _ = guardRemoteCacheDisabled Unit

    require Some auth = api.getRemoteCacheApiAuthorization
    else failWithError "rsc: RSC Client not configured for pushing to the server"

    require Pass response =
        makeRoute api "blob"
        | buildHttpRequest
        | setMethod HttpMethodPost
        | addAuthorizationHeader auth
        | setBlob
        | setTimeout api.getRemoteCacheApiMaxTime api.getRemoteCacheApiConnectTime
        | makeRequest
        | matchRequestResult "blob upload"

    require (Some 200) = response.getHttpResponseStatusCode
    else
        failWithError
        "rsc: failed to upload string as blob with code {response.getHttpResponseStatusCode | format}"

    require Pass json = response.getHttpResponseBody.parseJSONBody

    require Pass (JString "Ok") = jField json "type"
    else failWithError "rsc: failed to upload blob"

    require Pass (JArray blobs) = jField json "blobs"
    else failWithError "rsc: JSON response has incorrect schema for blob upload. (Missing blobs key)"

    def idJVals =
        blobs
        | map (jField _ "id")

    require Pass ids = idJVals.findFail
    else failWithError "rsc: JSON response has incorrect schema for blob upload. (Missing blob ids)"

    require ((JString id), Nil) = ids
    else
        failWithError
        "rsc: JSON response has incorrect schema for blob upload. (Expected only 1 id saw {ids.len.str})"

    Pass id

# Converts a CacheSearchRequest to JSON
def getCacheSearchRequestJson (req: CacheSearchRequest): JValue =
    def (CacheSearchRequest _label cmd cwd env hiddenInfo isAtty stdin visibleFiles) = req

    JObject (
        "cmd" :-> JArray (cmd.asBytesDelimedByNull | map JInteger),
        "cwd" :-> JString cwd,
        "env" :-> JArray (env.asBytesDelimedByNull | map JInteger),
        "hidden_info" :-> JString hiddenInfo,
        "is_atty" :-> JBoolean isAtty,
        "stdin" :-> JString stdin,
        "visible_files" :-> JArray (visibleFiles | map getPathAsJson),
    )

def getCacheAllowedRequestJson (req: CacheAllowedRequest): JValue =
    def (
        CacheAllowedRequest
        label
        cmd
        cwd
        env
        hiddenInfo
        isAtty
        stdin
        visibleFiles
        status
        runtime
        cputime
        memory
        obytes
    ) = req

    JObject (
        "cmd" :-> JArray (cmd.asBytesDelimedByNull | map JInteger),
        "cwd" :-> JString cwd,
        "env" :-> JArray (env.asBytesDelimedByNull | map JInteger),
        "hidden_info" :-> JString hiddenInfo,
        "is_atty" :-> JBoolean isAtty,
        "stdin" :-> JString stdin,
        "visible_files" :-> JArray (visibleFiles | map getPathAsJson),
        "status" :-> JInteger status,
        "runtime" :-> JDouble runtime,
        "cputime" :-> JDouble cputime,
        "memory" :-> JInteger memory,
        "obytes" :-> JInteger obytes,
        "label" :-> JString label,
    )

# Converts a CachePostJobRequest to JSON
def getCachePostRequestJson (req: CachePostRequest): JValue =
    def (
        CachePostRequest
        label
        cmd
        cwd
        env
        hiddenInfo
        isAtty
        stdin
        visibleFiles
        outputDirs
        outputSymlinks
        outputFiles
        stdoutBlobId
        stderrBlobId
        status
        runtime
        cputime
        memory
        ibytes
        obytes
    ) = req

    def mkOutputFileJson (CachePostRequestOutputFile path mode blobId) =
        JObject (
            "path" :-> JString path,
            "mode" :-> JInteger mode,
            "blob_id" :-> JString blobId,
        )

    def mkOutputDirJson (CachePostRequestOutputDirectory path mode hidden) =
        JObject (
            "path" :-> JString path,
            "mode" :-> JInteger mode,
            "hidden" :-> JBoolean hidden,
        )

    def mkOutputSymlinkJson (CachePostRequestOutputSymlink path link) =
        JObject (
            "path" :-> JString path,
            "link" :-> JString link,
        )

    JObject (
        "cmd" :-> JArray (cmd.asBytesDelimedByNull | map JInteger),
        "cwd" :-> JString cwd,
        "env" :-> JArray (env.asBytesDelimedByNull | map JInteger),
        "hidden_info" :-> JString hiddenInfo,
        "is_atty" :-> JBoolean isAtty,
        "stdin" :-> JString stdin,
        "visible_files" :-> JArray (visibleFiles | map getPathAsJson),
        "output_dirs" :-> JArray (outputDirs | map mkOutputDirJson),
        "output_symlinks" :-> JArray (outputSymlinks | map mkOutputSymlinkJson),
        "output_files" :-> JArray (outputFiles | map mkOutputFileJson),
        "stdout_blob_id" :-> JString stdoutBlobId,
        "stderr_blob_id" :-> JString stderrBlobId,
        "status" :-> JInteger status,
        "runtime" :-> JDouble runtime,
        "cputime" :-> JDouble cputime,
        "memory" :-> JInteger memory,
        "ibytes" :-> JInteger ibytes,
        "obytes" :-> JInteger obytes,
        "label" :-> JString label,
    )

# Makes a CacheSearchResponse from json if possible
def mkCacheSearchResponse (json: JValue): Result CacheSearchResponse Error =
    require Pass (JString isMatch) = jField json "type"
    else failWithError "rsc: JSON response has incorrect schema. Must have string key 'type'"

    require True = isMatch ==* "Match"
    else Pass NoMatch

    def mkBlob (v: JValue): Result CacheSearchBlob Error =
        require Pass (JString id) = jField v "id"
        else failWithError "rsc: JSON response has incorrect schema. '{v | format}' must have string key 'id'"

        require Pass (JString url) = jField v "url"
        else failWithError "rsc: JSON response has incorrect schema. '{v | format}' must have string key 'url'"

        CacheSearchBlob id url
        | Pass

    require Pass stdoutBlobF = jField json "stdout_blob"
    else failWithError "rsc: JSON response has incorrect schema. Must have object key 'stdout_blob'"

    require Pass stderrBlobF = jField json "stderr_blob"
    else failWithError "rsc: JSON response has incorrect schema. Must have object key 'stderr_blob'"

    require Pass stdoutBlob = mkBlob stdoutBlobF
    require Pass stderrBlob = mkBlob stderrBlobF

    require Pass (JInteger status) = jField json "status"
    else failWithError "rsc: JSON response has incorrect schema. Must have integer key 'status'"

    require Pass (JDouble runtime) = jField json "runtime"
    else failWithError "rsc: JSON response has incorrect schema. Must have double key 'runtime'"

    require Pass (JDouble cputime) = jField json "cputime"
    else failWithError "rsc: JSON response has incorrect schema. Must have double key 'cputime'"

    require Pass (JInteger memory) = jField json "memory"
    else failWithError "rsc: JSON response has incorrect schema. Must have integer key 'memory'"

    require Pass (JInteger ibytes) = jField json "ibytes"
    else failWithError "rsc: JSON response has incorrect schema. Must have integer key 'ibytes'"

    require Pass (JInteger obytes) = jField json "obytes"
    else failWithError "rsc: JSON response has incorrect schema. Must have integer key 'obytes'"

    require Pass (JArray outputFiles) = jField json "output_files"
    else failWithError "rsc: JSON response has incorrect schema. Must have array key 'output_files'"

    require Pass (JArray outputSymlinks) = jField json "output_symlinks"
    else failWithError "rsc: JSON response has incorrect schema. Must have array key 'output_symlinks'"

    require Pass (JArray outputDirectories) = jField json "output_dirs"
    else failWithError "rsc: JSON response has incorrect schema. Must have array key 'output_dirs'"

    def mkOutputSymlink (v: JValue): Result CacheSearchOutputSymlink Error =
        require Pass (JString path) = jField v "path"
        else
            failWithError
            "rsc: JSON response has incorrect schema. output_symlinks[x] must have string key 'path'"

        require Pass (JString link) = jField v "link"
        else
            failWithError
            "rsc: JSON response has incorrect schema. output_symlinks[x] must have string key 'link'"

        CacheSearchOutputSymlink path link
        | Pass

    def mkOutputDirectory (v: JValue): Result CacheSearchOutputDirectory Error =
        require Pass (JString path) = jField v "path"
        else
            failWithError
            "rsc: JSON response has incorrect schema. output_directories[x] must have string key 'path'"

        require Pass (JInteger mode) = jField v "mode"
        else
            failWithError
            "rsc: JSON response has incorrect schema. output_directories[x] must have integer key 'mode'"

        require Pass (JBoolean hidden) = jField v "hidden"
        else
            failWithError
            "rsc: JSON response has incorrect schema. output_directories[x] must have boolean key 'hidden'"

        CacheSearchOutputDirectory path mode hidden
        | Pass

    def mkOutputFile (v: JValue): Result CacheSearchOutputFile Error =
        require Pass (JString path) = jField v "path"
        else
            failWithError
            "rsc: JSON response has incorrect schema. '{v | format}' in output_files must have string key 'path'"

        require Pass (JInteger mode) = jField v "mode"
        else
            failWithError
            "rsc: JSON response has incorrect schema. {v | format} in output_files must have integer key 'mode'"

        require Pass jblob = jField v "blob"
        else
            failWithError
            "rsc: JSON response has incorrect schema. '{v | format}' in output_files must have object key 'blob'"

        require Pass blob = mkBlob jblob

        CacheSearchOutputFile path mode blob
        | Pass

    require Pass csOutputFiles =
        outputFiles
        | map mkOutputFile
        | findFail

    require Pass csOutputSymlinks =
        outputSymlinks
        | map mkOutputSymlink
        | findFail

    require Pass csOutputDirectories =
        outputDirectories
        | map mkOutputDirectory
        | findFail

    CacheSearchResponseMatch
    csOutputSymlinks
    csOutputDirectories
    csOutputFiles
    stdoutBlob
    stderrBlob
    status
    runtime
    cputime
    memory
    ibytes
    obytes
    | Match
    | Pass
