# Copyright 2024 SiFive, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You should have received a copy of LICENSE.Apache2 along with
# this software. If not, you may obtain a copy at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

package wake

# TODO: Delete these once new json API is added to wake repo
def jField (jvalue: JValue) (key: String) =
    require JObject obj = jvalue
    else failWithError "not an object"

    require Some (Pair (Pair _ value) _) = find (_.getPairFirst ==~ key) obj
    else failWithError "key '{key}' not found"

    Pass value

def jInteger = match _
    Pass (JInteger x) -> Pass x
    Fail err -> Fail err
    _ -> failWithError "not an integer"

def jString = match _
    Pass (JString x) -> Pass x
    Fail err -> Fail err
    _ -> failWithError "not a string"

def jDouble = match _
    Pass (JDouble x) -> Pass x
    Fail err -> Fail err
    _ -> failWithError "not a number"

def jArray (fn: Result JValue Error => Result a Error) = match _
    Pass (JArray arr) ->
        map (fn _.Pass) arr
        | findFail
    Fail err -> Fail err
    _ -> failWithError "not an array"

def getPath input =
    require Pass elem = input

    jField elem "path"
    | jString

# wakeroot is the absolute sandbox-path from which input and output files will
# be interpreted as being relative to if they're in fact relative.
export def mkJobCacheRunner (hashFn: Result RunnerInput Error => Result String Error) (wakeroot: String) ((Runner name score baseDoIt): Runner): Runner =
    def virtual job stdout stderr status runtime cputime membytes ibytes obytes = prim "job_virtual"
    def badlaunch job error = prim "job_fail_launch"
    def job_cache_read str = prim "job_cache_read"
    def job_cache_add str = prim "job_cache_add"

    def doit job runnerInput = match runnerInput
        Fail e ->
            def _ = badlaunch job e

            Fail e
        Pass (RunnerInput label cmd vis env dir stdin _ prefix _ _) ->
            def mkVisJson (Path path hash) =
                JObject (
                    "path" :-> JString path,
                    "hash" :-> JString hash,
                )

            def jobCacheVisible = JArray (map mkVisJson vis)

            require Pass hashKey = hashFn runnerInput

            def jobCacheJsonIn =
                prettyJSON
                $ JObject (
                    "wakeroot" :-> JString wakeroot,
                    "cwd" :-> JString dir,
                    "command_line" :-> JString cmd.implodeNull,
                    "environment" :-> JString env.implodeNull,
                    "stdin" :-> JString stdin,
                    "input_files" :-> jobCacheVisible,
                    "client_cwd" :-> JString workspace,
                    "runner_hash" :-> JString hashKey,
                    "dir_redirects" :-> JObject (wakeroot :-> JString "./",),
                )

            require Pass cacheResult =
                job_cache_read jobCacheJsonIn
                | rmapFail failWithError

            require Pass jobCacheJsonOut = parseJSONBody cacheResult

            require Pass (JBoolean cacheHit) = jField jobCacheJsonOut "found"
            else failWithError "job-cache returned unexpected json schema"

            def isDebugOn =
                require Some value = getenv "DEBUG_WAKE_SHARED_CACHE"
                else False

                value ==~ "1"

            require False = cacheHit
            else
                def _ =
                    require True = isDebugOn

                    def _ = write ".cache-hit/read.{prefix}.json" "//{label}\n{jobCacheJsonIn}"
                    def _ = write ".cache-hit/out.{prefix}.json" "//{label}\n{cacheResult}"

                    True

                require Pass match_info = jField jobCacheJsonOut "match"
                require Pass output_info = jField match_info "output_info"

                require Pass status =
                    jField output_info "status"
                    | jInteger

                require Pass runtime =
                    jField output_info "runtime"
                    | jDouble

                require Pass cputime =
                    jField output_info "cputime"
                    | jDouble

                require Pass mem =
                    jField output_info "mem"
                    | jInteger

                require Pass ibytes =
                    jField output_info "ibytes"
                    | jInteger

                require Pass obytes =
                    jField output_info "obytes"
                    | jInteger

                require Pass inputs =
                    jField match_info "input_files"
                    | jArray jString

                require Pass output_files =
                    jField match_info "output_files"
                    | jArray getPath

                require Pass output_dirs =
                    jField match_info "output_dirs"
                    | jArray getPath

                require Pass output_symlinks =
                    jField match_info "output_symlinks"
                    | jArray getPath

                require Pass stdout =
                    jField output_info "stdout"
                    | jString

                require Pass stderr =
                    jField output_info "stderr"
                    | jString

                def outputs = output_files ++ output_dirs ++ output_symlinks
                def predict = Usage status runtime cputime mem ibytes obytes
                def _ = virtual job stdout stderr status runtime cputime mem ibytes obytes

                Pass (RunnerOutput inputs outputs predict)

            def _ =
                require True = isDebugOn

                def _ = write ".cache-misses/read.{prefix}.json" "//{label}\n{jobCacheJsonIn}"

                True

            # Now we need to run the job
            require Pass (RunnerOutput inputs outputs useage) = baseDoIt job runnerInput

            def Usage status runtime cputime mem ibytes obytes = useage
            def inputsTree = listToTree scmpCanonical inputs

            def mkOutputFileJson src =
                JObject (
                    "src" :-> JString src,
                    "path" :-> JString "{wakeroot}/{src}",
                )

            def jobCacheOutputFiles = JArray (map mkOutputFileJson outputs)

            def jobCacheReadFiles =
                def readPaths = filter (tcontains _.getPathName inputsTree) vis

                JArray (map mkVisJson readPaths)

            require Pass stdout = getJobFailedStdout job
            require Pass stderr = getJobFailedStderr job

            def jobCacheAddJson =
                prettyJSON
                $ JObject (
                    "wakeroot" :-> JString wakeroot,
                    "cwd" :-> JString dir,
                    "command_line" :-> JString cmd.implodeNull,
                    "environment" :-> JString env.implodeNull,
                    "stdin" :-> JString stdin,
                    "runner_hash" :-> JString hashKey,
                    "input_files" :-> jobCacheReadFiles,
                    "input_dirs" :-> JArray Nil, # TODO: This will need some fuse work to make good on
                    "output_files" :-> jobCacheOutputFiles,
                    "status" :-> JInteger status,
                    "runtime" :-> JDouble runtime,
                    "cputime" :-> JDouble cputime,
                    "mem" :-> JInteger mem,
                    "ibytes" :-> JInteger ibytes,
                    "obytes" :-> JInteger obytes,
                    "stdout" :-> JString stdout,
                    "stderr" :-> JString stderr,
                    "client_cwd" :-> JString workspace,
                )

            # We put this in a def so that it does not block the return below.
            # This ensures that the effect still occurs and blocks wake finishing but the job
            # itself is not blocked by writing to the cache. This allows us to tolorate a lot
            # of slow down on cache writing.
            def _ =
                def _ =
                    require True = isDebugOn

                    def _ = write ".cache-misses/write.{prefix}.json" "//{label}\n{jobCacheAddJson}"

                    True

                # Caching a failed job is a waste of space, never do that
                require True = status == 0
                else Pass ""

                # Sometimes we want a read-only cache. For instance read-only pre-merge
                # with read-write post-merge.
                require None = getenv "WAKE_LOCAL_JOB_CACHE_READ_ONLY"
                else Pass ""

                job_cache_add jobCacheAddJson

            Pass (RunnerOutput (map getPathName vis) outputs useage)

    Runner "job-cache: {name}" score doit
