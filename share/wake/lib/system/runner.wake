# Copyright 2024 SiFive, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You should have received a copy of LICENSE.Apache2 along with
# this software. If not, you may obtain a copy at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

package wake

from remote_cache import rscRunner makeRemoteCacheApi

# Unknown quantities are 0
export tuple Usage =
    export Status: Integer
    export Runtime: Double
    export CPUtime: Double
    export MemBytes: Integer
    export InBytes: Integer
    export OutBytes: Integer

export def getUsageThreads (Usage _ run cpu _ _ _: Usage): Double =
    if run ==. 0.0 then
        cpu
    else
        cpu /. run

# RunnerInput is a subset of the fields supplied in the execution Plan
export tuple RunnerInput =
    export Label: String
    export Command: List String
    export Visible: List Path
    export Environment: List String
    export Directory: String
    export Stdin: String
    export Resources: List String
    # A unique prefix for this job
    export Prefix: String
    # Previous resource usage
    export Record: Usage
    # Determines if job should run in psuedoterminal
    export IsAtty: Boolean
    # Modify the Runner's reported inputs (files read).
    # Must be called exactly once for a given job.
    #
    # FnInputs may only be called once as the user provided function may not be idempotent.
    # Ex: FnInputs = tail being called multiple times would drop an extra file each time its called
    #     while the user only intentded for the very first file to be dropped
    #
    # Note for wrapping runners:
    #     It is expected that a wrapping runner maintain this invariant. What that looks like will
    #     depend heavily on the wrapper and requires due diligence. A cache wrapper for example
    #     should pass it along unmodified since it doesn't care about the actual inputs while
    #     a smart wrapper tracking file reads must pass a no-op function to the inner runner
    #     so that it can apply filtering after collecting the files read.
    export FnInputs: (List String => List String)
    # Modify the Runner's reported outputs (files created).
    # Must be called exactly once for a given job.
    #
    # FnOutputs may only be called once as the user provided function may not be idempotent.
    # Ex: FnOutputs = tail being called multiple times would drop an extra file each time its called
    #     while the user only intentded for the very first file to be dropped
    #
    # Note for wrapping runners:
    #     It is expected that a wrapping runner maintain this invariant. What that looks like will
    #     depend heavily on the wrapper and requires due diligence. A cache wrapper for example
    #     should pass it along unmodified since it doesn't care about the actual outputs while
    #     a smart wrapper tracking file writes must pass a no-op function to the inner runner
    #     so that it can apply filtering after collecting the files written.
    export FnOutputs: (List String => List String)

# The result returned by a Runner after running a job
export tuple RunnerOutput =
    # The filtered list of files actually read by the job. It can be used for more precise reruns
    export Inputs: List String
    # The filtered list of files output by the job. These files are hashed and elevated to Path
    export Outputs: List String
    # The list of files output by the job that should be deleted by wake --clean. May include files
    # listed in Outputs as they will be removed later. The files in the list that are not in
    # Outputs will not be hashed, published, or elevated to Path but will be deleted by wake --clean
    export CleanableOutputs: List String
    # The actual resource usage of the job that will be written to the database
    export Usage: Usage
    # The runner status code (0 for success, non-zero for failure)
    export RunnerStatus: Integer

# A Runner describes a way to invoke a Plan to get a Job
export tuple Runner =
    export Name: String
    Fn: Job => Result RunnerInput Error => Result RunnerOutput Error

# makeRunner: Hides some of the boiler plate required to create a runner
#
# This function requires very advanced wake experience and should be used with the greatest amount
# of caution. Callers must ensure at the very least that `run` calls primJobLaunch and one of the
# many job "wait" functions. Historically runners allowed dispatching to an arbirary "base" or
# "inner" runner. This significantly complicated the system and led to very unexpected interactions.
# It is recomennded that runners don't accept an "inner" runner and instead directly call the job
# primatives. If wrapping is unavoidable then the specific runner being wrapped should be named
# instead of accepting an arbitrary runner parameter.
#
# localRunner is a good reference implementation of the run function.
export def makeRunner (name: String) (run: Job => RunnerInput => Result RunnerOutput Error): Runner =
    def do job maybeInput = match maybeInput
        Fail e ->
            def _ = primJobFailLaunch job e

            Fail e
        Pass input -> run job input

    Runner name do

# localRunner: A runner that provides no sandboxing protections and no file tracking.
#
# You must use Fn{Inputs,Outputs} to fill in this information for wake to maintain safety and reusability
# Advanced usage only, proceed with caution
export def localRunner: Runner =
    def run (job: Job) ((RunnerInput _ cmd vis env dir stdin _ _ predict isAtty fnInputs fnOutputs): RunnerInput): Result RunnerOutput Error =
        def jobKey = JobKey dir stdin env.implode cmd.implode 0 "" isAtty.booleanToInteger
        def _ = primJobLaunch job jobKey predict

        def fileInputs =
            vis
            | map getPathName
            | fnInputs

        # Wait for the job to complete before calling fnOutputs
        require Pass reality = job.getJobReality

        # Check for runner errors and set runner status accordingly
        # Situations:
        # 1. Job succeeds, no runner error -> runner status = 0 (success)
        # 2. Job fails, no runner error -> runner status = 0 (success)
        # 3. Job succeeds, runner error -> runner status = 1 (failure)
        # 4. Job fails, runner error -> runner status = job status
        def runnerStatus = match (getJobRunnerError job)
            Pass errorMsg if errorMsg !=* "" ->
                # Log the runner error at the appropriate level
                def _ = printlnLevel logRunnerError "Runner error detected: {errorMsg}"

                # If job succeeded (status 0) but there's a runner error,
                # TODO: figure out if we need to account for this situation
                if reality.getUsageStatus == 0 then
                    1
                else
                    reality.getUsageStatus
            _ -> 0

        def _ = primJobSetRunnerStatus job runnerStatus

        # Caller needs to fill this in from nothing
        def cleanable = Nil
        def fileOutputs = fnOutputs cleanable

        RunnerOutput fileInputs fileOutputs cleanable reality runnerStatus
        | Pass

    makeRunner "local" run

# virtualRunner: A runner that immediatly marks the job as complete using the predicted usage
#
# This runner is useful for tracking a unit of work that is job like but not launched as a process
export def virtualRunner: Runner =
    def run (job: Job) ((RunnerInput _ _ vis _ _ _ _ _ predict _ fnInputs fnOutputs): RunnerInput): Result RunnerOutput Error =
        def _ = primJobVirtual job "" "" predict

        def fileInputs =
            vis
            | map getPathName
            | fnInputs

        # Wait for the job to complete before calling fnOutputs
        require Pass reality = job.getJobReality

        def runnerStatus = 0
        def _ = primJobSetRunnerStatus job runnerStatus

        # Caller needs to fill this in from nothing
        def cleanable = Nil
        def fileOutputs = fnOutputs cleanable

        RunnerOutput fileInputs fileOutputs cleanable reality runnerStatus
        | Pass

    makeRunner "virtual" run

# wrapRunner: Deprecated. Do not use this function.
#
# It will be deleted in the next release. See makeRunner for migration
export def wrapRunner name pre post (Runner _ run) =
    def doit job preInput = match (pre preInput)
        Pair runInput state ->
            def runOutput = run job runInput
            def final _ = post (Pair runOutput state)

            # Don't run any 'post' steps until the Job has stopped running
            waitJobMerged final job

    Runner name doit

# Implement FUSE-based Runner
export def fuseRunner: Runner =
    def fuse = "{wakePath}/wakebox"

    makeJSONRunnerPlan fuse
    | editJSONRunnerPlanExtraEnv (editEnvironment "DEBUG_FUSE_WAKE" (\_ getenv "DEBUG_FUSE_WAKE"))
    | makeJSONRunner

export def defaultRunner: Runner =
    require Some config = getenv "WAKE_REMOTE_CACHE"
    else
        require Some _ = getenv "WAKE_LOCAL_JOB_CACHE"
        else fuseRunner

        # The fuseRunner does not actully mount over / and instead uses the
        # the host root as the sandbox root. This means that wakeroot will
        # change from depending on where wake is being run from. As a hack
        # to work around this we abuse the fact that the fuseRunner only
        # works in relative paths to make different runs consistent. Ideally
        # you'd have a more complex sandbox that kept the wakeroot at a
        # consistent place across runs.
        mkJobCacheRunner (\_ Pass "") "/workspace" fuseRunner

    match (makeRemoteCacheApi config)
        Pass api -> rscRunner api
        Fail (Error why _) ->
            def _ =
                printlnLevel logError "Remote Cache requested, but unavailable. Continuing anyways. Why: '{why}'"

            fuseRunner

# A plan describing how to construct a JSONRunner
# RawScript: the path to the script to run jobs with
# ExtraArgs: extra arguments to pass to ``RawScript``
# ExtraEnv: environment variables to pass to the script
# Estimate: predict local usage based on prior recorded usage
tuple JSONRunnerPlan =
    export RawScript: String
    export ExtraArgs: List String
    export ExtraEnv: List String
    export Estimate: Usage => Usage

# make a ``JSONRunnerPlan`` with ``Nil`` and ``(_)`` as defaults for ``ExtraArgs`` and ``Estimate`` respectively
# rawScript: String; the path to the script to run jobs with
export def makeJSONRunnerPlan (rawScript: String): JSONRunnerPlan =
    JSONRunnerPlan rawScript Nil Nil (_)

# Make a Runner that runs a named script to run jobs
# plan: JSONRunnerPlan; a tuple containing the arguments for this function
export def makeJSONRunner ((JSONRunnerPlan rawScript extraArgs extraEnv estimate): JSONRunnerPlan): Runner =
    def script = which (simplify rawScript)
    def executeOk = access script xOK

    def run (job: Job) ((RunnerInput label command visible environment directory stdin res prefix record isatty fnInputs fnOutputs): RunnerInput): Result RunnerOutput Error =
        require True = executeOk
        else markJobSetupFailure job "Runner {script} is not executable".makeError

        def Usage status runtime cputime membytes inbytes outbytes = record

        def json =
            JObject (
                "label" :-> JString label,
                "command" :-> command | map JString | JArray,
                "environment" :-> environment | map JString | JArray,
                "visible" :-> visible | map (_.getPathName.JString) | JArray,
                "directory" :-> JString directory,
                "stdin" :-> JString stdin,
                "resources" :-> res | map JString | JArray,
                "version" :-> JString version,
                "isolate-network" :-> JBoolean False,
                "isolate-pids" :-> JBoolean False,
                "mount-ops" :-> JArray (JObject ("type" :-> JString "workspace", "destination" :-> JString ".", Nil), Nil),
                "usage" :-> JObject (
                    "status" :-> JInteger status,
                    "runtime" :-> JDouble runtime,
                    "cputime" :-> JDouble cputime,
                    "membytes" :-> JInteger membytes,
                    "inbytes" :-> JInteger inbytes,
                    "outbytes" :-> JInteger outbytes,
                    Nil
                ),
                Nil
            )

        def buildDirName = ".build"
        def specFile = "{buildDirName}/spec-{prefix}.json"
        def resultFile = "{buildDirName}/result-{prefix}.json"

        require Pass _ =
            write specFile (prettyJSON json)
            | addErrorContext "Failed to 'write {specFile}: '"
            | rmapFail (markJobSetupFailure job)

        def cmd = script, "-I", "-p", specFile, "-o", resultFile, extraArgs

        # Rewrite input so that the local runner can run the job with a configured sandbox
        # The identity function is passsed to the file input/output filters so no info is lost
        def localInput =
            RunnerInput
            label
            cmd
            Nil
            (extraEnv ++ environment)
            "."
            ""
            Nil
            prefix
            (estimate record)
            isatty
            identity
            identity

        # Dispatch to the local runner via composition and get the outputs
        def (Runner _ localRun) = localRunner

        require Pass localOutput = localRun job (Pass localInput)

        def statusCode = localOutput.getRunnerOutputUsage.getUsageStatus
        def runnerStatus = localOutput.getRunnerOutputRunnerStatus

        require 0 = statusCode
        else failWithError "Non-zero exit status ({str statusCode}) for JSON runner {script} on {specFile}"

        require Pass content = parseJSONFile (Path resultFile "BadHash")

        def _ = markFileCleanable resultFile

        def field name = match _ _
            _ (Fail f) -> Fail f
            None (Pass fn) -> Fail "{script} produced {resultFile}, which is missing usage/{name}"
            (Some x) (Pass fn) -> Pass (fn x)

        def usage = content // `usage`

        def usageResult =
            Pass (Usage _ _ _ _ _ _)
            | field "status" (usage // `status` | getJInteger)
            | field "runtime" (usage // `runtime` | getJDouble)
            | field "cputime" (usage // `cputime` | getJDouble)
            | field "membytes" (usage // `membytes` | getJInteger)
            | field "inbytes" (usage // `inbytes` | getJInteger)
            | field "outbytes" (usage // `outbytes` | getJInteger)

        def getK exp =
            content // exp
            | getJArray
            | getOrElse Nil
            | mapPartial getJString

        def jsonInputs = getK `inputs`
        def jsonOutputs = getK `outputs`
        def filteredInputs = fnInputs jsonInputs
        def filteredOutputs = fnOutputs jsonOutputs

        match usageResult
            Fail f -> Fail (makeError f)
            Pass usage ->
                Pass (RunnerOutput filteredInputs filteredOutputs jsonOutputs usage runnerStatus)

    makeRunner "json-{script}" run
